<html>
<head>

</head>
<body>
<script src="feature1.js">
</script>
<p>
ikuyysvbdkuyrvds
rysybd
dbyrybdr
trb
ybrs
byyyyyyyyyyye
yse
bysyyyyyyye
ANDROID SECURITY
App review before distribution -iOS: Apple manual and automated vetting; Android -  Easier to get app placed on market,Transparent automated scanning, removal via Bouncer
App isolation and protection - Sandboxing and restricted permission ;Android - Permission model ( runtime, dangerous/ normal) ,Defense against circumvention.
ANDROID CORE SECURITY FEATURES:
•	The Android Application Sandbox, isolates app data and code execution from other apps.
•	App framework with Implementations of common security functionality such as cryptography, permissions, and secure IPC.
•	Technologies like ASLR, NX, ProPolice, safe_iop, OpenBSD dlmalloc, OpenBSD calloc, and Linux mmap_min_addr to mitigate risks associated with common memory management errors.
•	An encrypted file system that can be enabled
•	User-granted permissions to restrict access to system features and user data.
•	Application-defined permissions to control application data on a per-app basis.
THREATS TO MOBILE APPLICATIONS:
•	Privacy: Data leakage, identifier leakage, third-party tags and libraries, location privacy
•	Security: Phishing, malware & drive-bys, malicious intents on Android, Ikee/Zitmo and other mobile malware.
OWASP Mobile Top Ten:
M1This category covers misuse of a platform feature or failure to use platform security controls. It might include Android intents, platform permissions, misuse of TouchID, the Keychain, or some other security control that is part of the mobile operating system. There are several ways that mobile apps can experience this risk.
M2: This new category is a combination of M2 + M4 from Mobile Top Ten 2014. This covers insecure data storage and unintended data leakage.
M3: This covers poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
M4: This category captures notions of authenticating the end user or bad session management. This can include:
Failing to identify the user at all when that should be required
Failure to maintain the user's identity when it is required
Weaknesses in session management
M5: Insufficient Cryptography : wrong crypto usage 
M6: Insecure Authorization
M7: Client Code Quality Issues : client side eg buffer overflows 
M8: Code Tampering : attacker nodification (code, memory etc) 
M9: Reverse Engineering : by attacker and gaining info 
M10: Extraneous Functionality : hidden back door or password in comment by mistake etc .
•	M1: misuse of a platform feature or failure to use platform security controls. egAndroid intents, platform permissions, misuse of TouchID, the Keychain, or some other security control 
•	M2: covers insecure data storage and unintended data leakage.
•	M3: poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
•	M4: authenticating end user or bad session management. This can include:Failing to identify the user at all when that should be required, Failure to maintain the user's identity when it is required. Weaknesses in session management.
MOBILE MALWARE EXAMPLES:
•	DroidDream (Android)
o	Over 58 apps uploaded to Google app market
o	Conducts data theft; send credentials to attacker
o	Trozan, gained root access
•	Ikee (iOS)
o	Worm capabilities (targeted default ssh pwd)
o	Worked only on jailbroken phones with ssh installed 
o	Zitmo (Symbian,BlackBerry,Windows,Android)
o	Propagates via SMS; claims to install a “security certificate”
o	Captures info from SMS; aimed at defeating 2-factor auth 
o	Works with Zeus botnet; timed with user PC infection.
COMPARISON BETWEEN PLATFORMS: 
•	Approval process for applications
o	Market: Vendor controlled/Open
o	App signing: Vendor-issued/self-signed
o	User approval of permission
•	Programming language for applications
o	Managed execution: Java, .Net 
o	Native execution: Objective C0.
ANDROID:
•	Platform outline:
o	Linux kernel, browser, SQL-lite database
o	Software for secure network communication
	Open SSL, Bouncy Castle crypto API and Java library 
o	C language infrastructure
o	Java platform for running applications
	Dalvik bytecode, virtual machine
                              ,         

ANDROID MARKET:
•	Self-signed apps
•	App permissions granted on user installation
•	Open market -  Bad applications may show up on market;Shifts focus from remote exploit to privilege escalation.
ANDROID PERMISSIONS:
•	Example of permissions provided by Android
o	“android.permission.INTERNET”
o	“android.permission.READ_EXTERNAL_STORAGE 
o	“android.permission.SEND_SMS”
o	“android.permission.BLUETOOTH” 
•	Also possible to define custom permissions
ANDROID PERMISSION MODEL:
Google maps or Uber asking for location permission to be switched on.
 
 
SECURITY FEATURES:
•	Isolation
o	Multi-user Linux operating system 
o	Each application normally runs as a different user
•	Communication between applications
o	May share same Linux user ID
	Access files from each other
	May share same Linux process and Dalvik VM
o	Communicate through application framework
	“Intents,” based on Binder, discussed in a few slides
•	Battery life
o	Developers must conserve power
o	Applications store state so they can be stopped (to save power) and restarted.
APPLICATION  SANDBOX:
o	Each application runs with its UID in its own Dalvik virtual machine
	Provides CPU protection, memory protection
	Authenticated communication protection using Unix domain sockets
	Only ping, zygote (spawn another process) run as root
o	Applications announce permission requirement
	Create a whitelist model – user grants access
	Don’t interrupt user  – all questions asked as install time
	Inter-component communication reference monitor checks permissions.
EXPLOIT PREVENTION:
	Open source: public review, no obscurity
	Goals
o	Prevent remote attacks, privilege escalation
o	Secure drivers, media codecs, new and custom features
	Overflow prevention
o	ProPolice stack protection
	First on the ARM architecture
o	Some heap overflow protections
	Chunk consolidation in DL malloc (from OpenBSD)
	ASLR (Address Space Layout Randomisation) 
o	Avoided in initial release
	Many pre-linked images for performance 
o	Later developed and contributed by Bojinov, Boneh.
DLMALLOC: 
	Stores meta data in band 
	Heap consolidation attack
o	Heap overflow can overwrite pointers to previous and next unconsolidated chunks
o	Overwriting these pointers allows remote code execution
	Change to improve security
o	Check integrity of forward and backward pointers
	Simply check that back-forward-back = back,  f-b-f=f
o	Increases the difficulty of heap overflow
APPLICATION DEVELOPMENT CONCEPTS:
	Activity – one-user task
o	Example: scroll through your inbox
o	Email client comprises many activities
	Service – Java daemon that runs in background
o	Example: application that streams an mp3 in background
	Intents – asynchronous messaging system
o	Fire an intent to switch from one activity to another
o	Example: email app has inbox, compose activity, viewer activity
	User click on inbox entry fires an intent to the viewer activity, which then allows user to view that email
	Content provider
o	Store and share data using a relational database interface 
	Broadcast receiver
o	 “mailboxes” for messages from other applications
ANDROID INTENTS: 
	Message between components in same or different app
	Intent is a bundle of information, e.g.,  
o	action to be taken
o	data to act on
o	category of component to handle the intent
o	instructions on how to launch a target activity
	Routing can be
o	Explicit: delivered only to a specific receiver 
o	Implicit: all components that have registered to receive that action will get the message
 
 
SECURITY ISSUES WITH INTENTS:
	Sender of an intent can verify that the recipient has a permission by specifying a permission with the method call
	Senders can use explicit intents to send the message to a single component (avoiding broadcasting)
	Receivers have to handle malicious intents
ATTACK : PERMISSION REDELEGATION
	Definition: an application without a permission gains additional privileges through another application 
	Example of the “confused deputy” problem 
   
	App w/ permissions exposes a public interface
	Study in 2011
o	Examine 872 apps
o	320 of these (37%) have permissions and at least one type of public component
o	Construct attacks using 15 vulnerabilities in 5 apps
POWER CONTROL WIDGET:
	Can change Wi-fi, BT, GPS, Data Sync, Screen Brightness with only one click 
	Uses Intent to communicate the event of switching settings
A malicious app without permissions can send a fake Intent to the Power Control Widget, simulating click to switch settings
Principle of least privilege works but is not a solution. Apps with permissions need to manage security.
JAVA SANDBOX:
	Four complementary mechanisms
o	Class loader
	Separate namespaces for separate class loaders
	Associates protection domain with each class 
o	Verifier and JVM run-time tests
	NO unchecked casts or other type errors, NO array overflow
	Preserves private, protected visibility levels
o	Security Manager
	Called by library functions to decide if request is allowed
	Uses protection domain associated with code, user policy
STACK INSPECTION: 
•	Permission depends on
o	Permission of calling method
o	Permission of all methods above it on stack
	Up to method that is trusted and asserts this trust 
MAC OS APPLICATION DEVELOPMENT:
•	Apps developed in Objective-C using Apple SDK
•	model based on touch events
•	FoundEvent-handling ation and UIKit frameworks provide the key services used by all iOS applications



MAC OS PLATFORM:
 

 

APP SECURITY:
•	Runtime protection
o	System resources, kernel shielded from user apps
o	App “sandbox” prevents access to other app’s data 
o	Inter-app communication only through iOS APIs 
o	Code generation prevented
•	Mandatory code signing
o	All apps must be signed using Apple-issued certificate
•	Application data protection
o	Apps can leverage built-in hardware encryption
IOS SANDBOX:
•	Limit app’s access to files, preferences, network, other resources
•	Each app has own sandbox directory
•	Limits consequences of attacks
•	Same privileges for each app
FILE ENCRYPTION:
•	The content of a file is encrypted with a per-file key, which is wrapped with a class key and stored in a file’s metadata, which is in turn encrypted with the file system key. 
o	When a file is opened, its metadata is decrypted with the file system key, revealing the wrapped per-file key and a notation on which class protects it 
o	The per-file key is unwrapped with the class key, then supplied to the hardware AES engine, decrypting the file as it is read from flash memory
•	The metadata of all files is encrypted with a random key. Since it’s stored on the device, used only for quick erased on demand.
 
MASQUE ATTACK:
•	iOS app installed using enterprise/ad-hoc provisioning could replace genuine app installed through the App Store, if both apps have same bundle identifier
•	This vulnerability existed because iOS didn't enforce matching certificates for apps with the same bundle identifier 
COMPARISON OF MAC OS VS ANDROID:
•	App approval process
o	Android apps from open app store
o	iOS vendor-controlled store of vetted apps
•	Application permissions
o	Android permission based on install-time manifest
o	All iOS apps have same set of “sandbox” privileges
•	App programming language
o	Android apps written in Java; no buffer overflow…
o	iOS apps written in Objective-C
	iOS	Android	Windows
Unix	x	x	
Windows			
Open market		x	
Closed market	x		
Vendor signed	x		
Self-signed		x	
User approval of permissions		x	
Managed code		x	
Native code	x		

MOST SIGNIFICANT VULNERABILITIES:
	Loading untrusted web content
	Leaking URLs to foreign apps
	Exposing state changing navigation to foreign apps


BUFFER OVERFLOW
EXPLANATION FOR LAST PROGRAM:
Figure 11.12a illustrates such a vulnerable program (which shares many similarities with Figure 11.11a, except that the structure is declared as a global variable). The design of the attack is very similar, indeed only the target address changes. The global structure was found to be at address 0x08049740, which was used as the target address in the attack. Note that global variables do not usually change location, as their addresses are used directly in the program code. The attack script and result of successfully executing it are shown in the text in Figure 11.12b.
MALICIOUS SOFTWARE:
	programs exploiting system vulnerabilities
	known as malicious software or malware 
o	program fragments that need a host program
	e.g. viruses, logic bombs, and backdoors 
o	independent self-contained programs
	e.g. worms, bots
o	replicating or not
	sophisticated threat to computer systems

MALWARE TECHNOLOGY:
	Mobile code software : can be shipped unchanged to a heterogeneous collection of platforms and execute with identical semantics
	Auto-rooter malicious hacker tools : used to break into new machines remotely Kit (virus generator) Set of tools for generating new viruses automatically 
	Spammer and Flooder programs : used to send large volumes of unwanted e-mail, or to attack systems with a large volumes of traffic to carry out a DoS attack.
VIRUS:
	piece of software that infects programs
o	modifying them to include a copy of the virus
o	so it executes secretly when host program is run
	specific to operating system and hardware
o	taking advantage of their details and weaknesses
	a typical virus goes through phases of:
o	dormant
o	propagation
o	triggering
o	execution
Email Viruses
A more recent development in malicious software is the e-mail virus. The first rapidly spreading e-mail viruses, such as Melissa, made use of a Microsoft Word macro embedded in an attachment. If the recipient opens the e-mail attachment, the Word macro is activated. Then the e-mail virus sends itself to everyone on the mailing list in the user's e-mail package, and also does local damage.
At the end of 1999, a more powerful version of the e-mail virus appeared. This newer version can be activated merely by opening an e-mail that contains the virus rather than opening an attachment. The virus uses the Visual Basic scripting language supported by the e-mail package.
Thus we see a new generation of malware that arrives via e-mail and uses e-mail software features to replicate itself across the Internet. The virus propagates itself as soon as activated (either by opening an e-mail attachment of by opening the e-mail) to all of the e-mail addresses known to the infected host. As a result, whereas viruses used to take months or years to propagate, they now do so in hours. This makes it very difficult for antivirus software to respond before much damage is done. Ultimately, a greater degree of security must be built into Internet utility and application software on PCs to counter the growing threat.
DIGITAL IMMUNE SYSTEM:
Comprehensive approach to virus protection developed by IBM and subsequently refined by Symantec
When a new virus enters an organization, the immune system automatically captures it, analyzes it, adds detection and shielding for it, removes it, and passes information about that virus to other systems so that it can be detected before it is allowed to run elsewhere
	1. A monitoring program on each PC uses a variety of heuristics to infer that a virus may be present, and forwards a copy to an administrative machine.
	2. The admin machine encrypts this and sends it to a central virus analysis machine.
	3. This machine creates an environment in which the infected program can be safely run for analysis. The virus analysis machine then produces a prescription for identifying and removing the virus.
	 4. The resulting prescription is sent back to the administrative machine. 
	5.  The administrative machine forwards the prescription to the infected client.
	 6. The prescription is also forwarded to other clients in the organization.
	 7. Subscribers worldwide receive regular antivirus updates to protect from new virus
The success of the digital immune system depends on the ability of the virus analysis machine to detect new and innovative virus strains.

  
 
BEHAVIOURAL BLOCKING SOFTWARE:
Unlike heuristics or fingerprint-based scanners, behavior-blocking software integrates with the operating system of a host computer and monitors program behavior in real-time for malicious actions. The behavior blocking software then blocks potentially malicious actions before they can affect the system. Monitored behaviors can include
• Attempts to open, view, delete, and/or modify files;
• Attempts to format disk drives and other unrecoverable disk operations;
• Modifications to the logic of executable files or macros;
• Modification of critical system settings, such as start-up settings;
• Scripting of e-mail and instant messaging clients to send executable content; and
• Initiation of network communications.
Figure 7.5 illustrates its operation. Behavior-blocking software runs on server and desktop computers and is instructed through policies set by the network administrator to let benign actions take place but to intercede when unauthorized or suspicious actions occur. The module blocks any suspicious software from executing. A blocker isolates the code in a sandbox, which restricts the code's access to various OS resources and applications. The blocker then sends an alert. Because behavior blocker can block suspicious software in real-time, it has an advantage over such established antivirus detection techniques as fingerprinting or heuristics. Behavior blocking alone has limitations. Because the malicious code must run on the target machine before all its behaviors can be identified, it can cause harm before it has been detected and blocked. 
MORRIS WORM: Until the current generation of worms, the best known was the worm released onto the Internet by Robert Morris in 1988. The Morris worm was designed to spread on UNIX systems and used a number of different techniques for propagation. When a copy began execution, its first task was to discover other hosts known to this host that would allow entry from this host. The worm performed this task by examining a variety of lists and tables, including system tables that declared which other machines were trusted by this host, users' mail forwarding files, tables by which users gave themselves permission for access to remote accounts, and from a program that reported the status of network connections. For each discovered host, the worm tried a number of methods for gaining access:
1.	 It attempted to log on to a remote host as a legitimate user, having cracked the local password file, and assuming that many users use the same password on different systems. 
2.	 It exploited a bug in the finger protocol
3.	It exploited a trapdoor in the debug option of the remote sendmail process.
If any of these attacks succeeded, the worm achieved communication with the operating system command interpreter. It then sent this interpreter a short bootstrap program, issued a command to execute that program, and then logged off. The bootstrap program then called back the parent program and downloaded the remainder of the worm. The new worm was then executed.
WORM COUNTERMEASURES:
There is considerable overlap in techniques for dealing with viruses and worms. Once a worm is resident on a machine, antivirus software can be used to detect it. In addition, because worms propagation generates considerable network activity, the monitoring of that activity can lead form the basis of a worm defense. Have classes: 
A.	Signature-based worm scan filtering: generates a worm signature, which is then used to prevent worm scans from entering/leaving a network/host. 
B.	Filter-based worm containment: focuses on worm content rather than a scan signature. The filter checks a message to determine if it contains worm code.
C.	Payload-classification-based worm containment: examine packets to see if they contain a worm using anomaly detection techniques 
D.	Threshold random walk (TRW) scan detection: exploits randomness in picking destinations to connect to as a way of detecting if a scanner is in operation 
E.	Rate limiting: limits the rate of scanlike traffic from an infected host. 
F.	Rate halting: immediately blocks outgoing traffic when a threshold is exceeded either in outgoing connection rate or diversity of connection attempts. Rate halting can integrate with a signature- or filter-based approach so that once a signature or filter is generated, every blocked host can be unblocked; as with rate limiting, rate halting techniques are not suitable for slow, stealthy worms. 

PROACTIVE WORM CONTAINMENT:
The Proactive Worm Containment (PWC) scheme is host based software that looks for surges in the rate of frequency of outgoing connection attempts and the diversity of connections to remote hosts. When such a surge is detected, the software immediately blocks its host from further connection attempts. A deployed PWC system consists of a PWC manager and PWC agents in hosts. Figure 7.7 from the text is an example of an architecture that includes PWC, which operates as detailed: 
A.	 A PWC agent monitors outgoing traffic for scan activity, determined by a surge in UDP / TCP connection attempts to remote hosts. If a surge is detected, the agent: 1) issues an alert to local system; 2) blocks all outgoing connection attempts; 3) transmits the alert to the PWC manager; and  4) starts a relaxation analysis. 
B. A PWC manager receives an alert, and propagates the alert to all other agents.
C. The host receives an alert, and must decide whether to ignore the alert. If the time since the last incoming packet has been sufficiently long so that the agent would have detected a worm if infected, then the alert is ignored. Otherwise, the agent assumes that it might be infected and performs the following actions:(1) blocks all outgoing connection attempts from the specific alerting port;and (2) starts a relaxation analysis. 
D. Relaxation analysis. An agent monitors outgoing activity for a fixed window of time to see if outgoing connections exceed a threshold. If so, blockage is continued and relaxation analysis is repeated until the outgoing connection rate drops below the threshold, at which time the agent removes the block. If the threshold continues to be exceeded over a sufficient number of relaxation windows, the agent isolates the host and reports to the PWC manager. 
Meanwhile, a signature extractor functions as a passive sensor that monitors all traffic and attempts to detect worms by signature analysis. 

NETWORK BASED WORM DEFENSE
The key element of a network-based worm defense is worm monitoring software. Two types of monitoring software are needed: 
• Ingress monitors: located at the border between the enterprise network and the Internet, in a border router, external firewall, separate passive monitor, or honeypot.
• Egress monitors: located at the egress point of individual LANs on the enterprise network as well as at the external border, in a LAN router or switch, external firewall or honeypot. The two types of monitors can be collocated. It is designed to catch the source of a worm attack by monitoring outgoing traffic for signs of scanning etc.
Worm monitors can act in the manner of intrusion detection systems and generate alerts to a central administrative system. It is also possible to implement a system that attempts to react in real time to a worm attack, so as to counter zero-day exploits effectively. This is similar to the approach taken with the digital immune system (Figure 7.4). Figure 7.8 shows an example of a worm countermeasure architecture that works as :
1.	Sensors deployed at various network locations detect a potential worm.
2. and send alerts to a central server that correlates / analyzes incoming alerts.
3. forwards info to a protected environment, where worm is sandboxed for analysis 
4. protected system tests the suspicious software against an appropriately instrumented version of the targeted application to identify the vulnerability. 
5. protected system generates one or more software patches and tests these.
6. system sends the patch to the application host to update the targeted application. 

INTERNET SECURITY PROTOCOLS AND STANDARDS
IPSec ensures TCP and application protocol is encrypted – and much of IP too.
With SSL or TLS, IP and TCP are not encrypted.
Benefits in routing applications:
	A routing advertisement : comes from an authorised router
	A neighbour advertisement
	A redirect message comes from router to which initial message was sent
	A routing update is not forged
	An ICMP redirect is an error message sent by a router to the sender of an IP packet . Redirects are used when a router believes a packet is being routed sub optimally and it would like to inform the sending host that it should forward subsequent packets to that same destination through a different gateway.
 

 
AUTHENTICATION HEADER: The Authentication Header provides support for data integrity and authentication of IP packets.The data integrity feature ensures that undetected modification to a packet’s content in transit is not possible. The authentication feature enables an end system or network device to authenticate the user or application and filter traffic accordingly; it also prevents address spoofing attacks and replay attacks. Authentication is based on the use of a message authentication code (MAC), hence the two parties must share a secret key. AH supports MACs using HMAC-MD5-96 or HMAC-SHA-1-96. Both of these use the HMAC algorithm , the first with the MD5 hash code and the second with the SHA-1 hash code. In both cases, the full HMAC value is calculated but then truncated by using the first 96-bits, which is the default length for the Authentication Data field.
ENCAPSULATION SECURITY PAYLOAD  (ESP):
	Provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality 
	As an optional feature, ESP can also provide an authentication service, with the same MACs as AH
	Padding used based on need on encryption algorithm used, also used for limited data confidentiality by concealing actual length of flow
 
Figure 21.4 shows the Authentication Header fields:
• Next Header (8 bits): Identifies the type of header immediately following this header
• Payload Length (8 bits): Length of Authentication Header in 32-bit words, minus 2. 
• Reserved (16 bits): For future use
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value
• Authentication Data (variable): A variable-length field (must be an integral number of 32-bit words) that contains the Integrity Check Value (ICV), or MAC,for this packet
The authentication data field is calculated over
• IP header fields that either do not change in transit (immutable) or that are predictable in value upon arrival at the endpoint for the AH SA. 
• The AH header other than the Authentication Data field. The Authentication Data field is set to zero for purposes of calculation at both source and destination. 
• The entire upper-level protocol data, which is assumed to be immutable in transit.

ENCAPSULATION SECURITY PAYLOAD:

The Encapsulating Security Payload provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality. As an optional feature, ESP can also provide an authentication service, with the same MACs as AH. ESP supports range of ciphers, modes, and padding, as shown.
 Figure 21.5 shows the format of an ESP packet. It contains the following fields:
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value; this provides an anti-replay function ,as discussed for AH
• Payload Data (variable): This is a transport-level segment (transport mode) or IP packet (tunnel mode) that is protected by encryption
• Padding (0–255 bytes): for various reasons
• Pad Length (8 bits): Indicates the number of pad bytes immediately preceding this field
• Next Header (8 bits): Identifies the type of data contained in the payload data field by identifying the first header in that payload 
• Authentication Data (variable): A variable-length field that contains the Integrity Check Value computed over the ESP packet minus the Authentication Data field 
TRANSPORT VS TUNNEL MODE:
Stallings Figure 16.5 shows the difference between end-to-end (transport) mode and end-to-intermediate (tunnel) mode.
Transport mode provides protection primarily for upper-layer protocol payloads, by inserting the AH after the original IP header and before the IP payload. Typically, transport mode is used for end-to-end communication between two hosts.
Tunnel mode provides protection to the entire IP, after the AH or ESP fields are added to the IP packet, the entire packet plus security fields is treated as the payload of new “outer”IP packet with a new outer IP header. Tunnel mode is used when one or both ends of an SA are a security gateway, such as a firewall or router that implements IPSec. 


 
 

 
KEY MANAGEMENT:
The key management portion of IPSec involves the determination and distribution of secret keys. A typical requirement is four keys for communication between two applications: transmit and receive pairs for both AH and ESP. The IPSec Architecture document mandates support for two types of key management:
• Manual where a system administrator manually configures each system with its own keys and with the keys of other communicating 
• Automated where an automated system enables the on-demand creation of keys for SAs and facilitates the use of keys in a large distributed system with an evolving configuration
The default automated key management protocol for IPSec is referred to as ISAKMP/Oakley.
Default Key Management protocol for IPSEC is ISAKMP/Oakley. Following elements
	Oakley Key Determination protocol : Based on Diffie-Hellman algorithm but providing added security to avoid man in middle attack
	Internet Security Association and Key Management Protocol (ISAKMP) Framework for Internet Key management and provides specific protocol support 


PUBLIC KEY ENCRYPTION:
Main Characteristics or differentiating factors
	Digest Length
	Basic Unit of processing ( input block length )
	Number of steps
	Maximum message size
	Number of primitive logical functions
	Number of additive constants used
HMAC: In recent years, there has been increased interest in developing a MAC derived from a cryptographic hash code, such as SHA-1, since these are usually faster, and code is widely available. A hash function such as SHA-1 was not designed for use as a MAC and cannot be used directly for that purpose because it does not rely on a secret key. There have been a number of proposals for the incorporation of a secret key into an existing hash algorithm. The approach that has received the most support is HMAC. 
HMAC has been issued as RFC 2104, has been chosen as the mandatory-to-implement MAC for IP Security, and is used in other Internet protocols, such as Transport Layer Security (TLS, soon to replace Secure Sockets Layer) and Secure Electronic Transaction (SET). HMAC treats the hash function as a "black box." This has two benefits. First, an existing implementation of a hash function can be used as a module in implementing HMAC. In this way, the bulk of the HMAC code is prepackaged and ready to use without modification. Second, if it is ever desired to replace a given hash function in an HMAC implementation, all that is required is to remove the existing hash function module and drop in the new module. This could be done if a faster hash function were desired. More important, if the security of the embedded hash function were compromised, the security of HMAC could be retained simply by replacing the embedded hash function with a more secure one. Also, HMAC can be proven secure provided that the embedded hash function has some reasonable cryptographic strengths. 
CRYPTOGRAPHIC HASH FUNCTION – HMAC :
Design Objectives
	Developing MAC from Cryptographic hash code ( relies on secret key)
	To be able to use existing hash functions without modification
	Allow easy replaceability of embedded hash function in case faster or more secure functions are found
	No degradation on performance from original hash function
	Handle keys in a simple way
	Well understood analysis of strength of authentication mechanism


STACK SMASHING
             
	`Smash the stack` [C programming] n. On many C implementations
	it is possible to corrupt the execution stack by writing past
	the end of an array declared auto in a routine.  Code that does
	this is said to smash the stack, and can cause return from the
	routine to jump to a random address.  This can produce some of
	the most insidious data-dependent bugs known to mankind.
	Variants include trash the stack, scribble the stack, mangle
	the stack; the term mung the stack is not used, as this is
	never done intentionally. See spam; see also alias bug,
	fandango on core, memory leak, precedence lossage, overrun screw.

INTRODUCTION
   Over the last few months there has been a large increase of buffer
overflow vulnerabilities being both discovered and exploited.  Examples
of these are syslog, splitvt, sendmail 8.7.5, Linux/FreeBSD mount, Xt 
library, at, etc.  This paper attempts to explain what buffer overflows 
are, and how their exploits work.

   Basic knowledge of assembly is required.  An understanding of virtual 
memory concepts, and experience with gdb are very helpful but not necessary.
We also assume we are working with an Intel x86 CPU, and that the operating 
system is Linux.

   Some basic definitions before we begin: A buffer is simply a contiguous 
block of computer memory that holds multiple instances of the same data 
type.  C programmers normally associate with the word buffer arrays. Most 
commonly, character arrays.  Arrays, like all variables in C, can be 
declared either static or dynamic.  Static variables are allocated at load 
time on the data segment.  Dynamic variables are allocated at run time on 
the stack. To overflow is to flow, or fill over the top, brims, or bounds. 
We will concern ourselves only with the overflow of dynamic buffers, otherwise
known as stack-based buffer overflows.


                          Process Memory Organization
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~

   To understand what stack buffers are we must first understand how a
process is organized in memory.  Processes are divided into three regions:
Text, Data, and Stack.  We will concentrate on the stack region, but first
a small overview of the other regions is in order.

   The text region is fixed by the program and includes code (instructions)
and read-only data.  This region corresponds to the text section of the
executable file.  This region is normally marked read-only and any attempt to
write to it will result in a segmentation violation.

   The data region contains initialized and uninitialized data.  Static
variables are stored in this region.  The data region corresponds to the
data-bss sections of the executable file.  Its size can be changed with the
brk(2) system call.  If the expansion of the bss data or the user stack
exhausts available memory, the process is blocked and is rescheduled to
run again with a larger memory space. New memory is added between the data
and stack segments.

                             /------------------\  lower
                             |                  |  memory
                             |       Text       |  addresses
                             |                  |
                             |------------------|
                             |   (Initialized)  |
                             |        Data      |
                             |  (Uninitialized) |
                             |------------------|
                             |                  |
                             |       Stack      |  higher
                             |                  |  memory
                             \------------------/  addresses

                         Fig. 1 Process Memory Regions


                               What Is A Stack?
                               ~~~~~~~~~~~~~~~~

   A stack is an abstract data type frequently used in computer science.  A
stack of objects has the property that the last object placed on the stack
will be the first object removed.  This property is commonly referred to as
last in, first out queue, or a LIFO.

   Several operations are defined on stacks.  Two of the most important are
PUSH and POP.  PUSH adds an element at the top of the stack.  POP, in 
contrast, reduces the stack size by one by removing the last element at the 
top of the stack.


                            Why Do We Use A Stack?
                            ~~~~~~~~~~~~~~~~~~~~~~

   Modern computers are designed with the need of high-level languages in
mind.  The most important technique for structuring programs introduced by
high-level languages is the procedure or function.  From one point of view, a
procedure call alters the flow of control just as a jump does, but unlike a
jump, when finished performing its task, a function returns control to the 
statement or instruction following the call.  This high-level abstraction
is implemented with the help of the stack.

  The stack is also used to dynamically allocate the local variables used in
functions, to pass parameters to the functions, and to return values from the
function.


                               The Stack Region
                               ~~~~~~~~~~~~~~~~

   A stack is a contiguous block of memory containing data.  A register called
the stack pointer (SP) points to the top of the stack.  The bottom of the 
stack is at a fixed address.  Its size is dynamically adjusted by the kernel 
at run time. The CPU implements instructions to PUSH onto and POP off of the 
stack. 

   The stack consists of logical stack frames that are pushed when calling a
function and popped when returning.  A stack frame contains the parameters to 
a function, its local variables, and the data necessary to recover the 
previous stack frame, including the value of the instruction pointer at the 
time of the function call.

   Depending on the implementation the stack will either grow down (towards
lower memory addresses), or up.  In our examples we'll use a stack that grows
down.  This is the way the stack grows on many computers including the Intel, 
Motorola, SPARC and MIPS processors.  The stack pointer (SP) is also
implementation dependent.  It may point to the last address on the stack, or 
to the next free available address after the stack.  For our discussion we'll
assume it points to the last address on the stack.

   In addition to the stack pointer, which points to the top of the stack
(lowest numerical address), it is often convenient to have a frame pointer
(FP) which points to a fixed location within a frame.  Some texts also refer
to it as a local base pointer (LB).  In principle, local variables could be
referenced by giving their offsets from SP.  However, as words are pushed onto
the stack and popped from the stack, these offsets change.  Although in some
cases the compiler can keep track of the number of words on the stack and
thus correct the offsets, in some cases it cannot, and in all cases
considerable administration is required.  Futhermore, on some machines, such
as Intel-based processors, accessing a variable at a known distance from SP
requires multiple instructions.

   Consequently, many compilers use a second register, FP, for referencing
both local variables and parameters because their distances from FP do
not change with PUSHes and POPs.  On Intel CPUs, BP (EBP) is used for this 
purpose.  On the Motorola CPUs, any address register except A7 (the stack 
pointer) will do.  Because the way our stack grows, actual parameters have 
positive offsets and local variables have negative offsets from FP.

   The first thing a procedure must do when called is save the previous FP
(so it can be restored at procedure exit).  Then it copies SP into FP to 
create the new FP, and advances SP to reserve space for the local variables. 
This code is called the procedure prolog.  Upon procedure exit, the stack 
must be cleaned up again, something called the procedure epilog.  The Intel 
ENTER and LEAVE instructions and the Motorola LINK and UNLINK instructions, 
have been provided to do most of the procedure prolog and epilog work 
efficiently. 

   Let us see what the stack looks like in a simple example:

example1.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
}

void main() {
  function(1,2,3);
}
------------------------------------------------------------------------------

   To understand what the program does to call function() we compile it with
gcc using the -S switch to generate assembly code output:

$ gcc -S -o example1.s example1.c

   By looking at the assembly language output we see that the call to
function() is translated to:

        pushl $3
        pushl $2
        pushl $1
        call function

    This pushes the 3 arguments to function backwards into the stack, and
calls function().  The instruction 'call' will push the instruction pointer
(IP) onto the stack.  We'll call the saved IP the return address (RET).  The
first thing done in function is the procedure prolog:

        pushl %ebp
        movl %esp,%ebp
        subl $20,%esp

   This pushes EBP, the frame pointer, onto the stack.  It then copies the
current SP onto EBP, making it the new FP pointer.  We'll call the saved FP
pointer SFP.  It then allocates space for the local variables by subtracting
their size from SP.

   We must remember that memory can only be addressed in multiples of the
word size.  A word in our case is 4 bytes, or 32 bits.  So our 5 byte buffer
is really going to take 8 bytes (2 words) of memory, and our 10 byte buffer
is going to take 12 bytes (3 words) of memory.  That is why SP is being
subtracted by 20.  With that in mind our stack looks like this when
function() is called (each space represents a byte):


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]
	   
top of                                                            bottom of
stack                                                                 stack


                               Buffer Overflows
                               ~~~~~~~~~~~~~~~~

   A buffer overflow is the result of stuffing more data into a buffer than
it can handle.  How can this often found programming error can be taken
advantage to execute arbitrary code?  Lets look at another example:

example2.c
------------------------------------------------------------------------------
void function(char *str) {
   char buffer[16];

   strcpy(buffer,str);
}

void main() {
  char large_string[256];
  int i;

  for( i = 0; i < 255; i++)
    large_string[i] = 'A';

  function(large_string);
}
------------------------------------------------------------------------------

   This is program has a function with a typical buffer overflow coding
error.  The function copies a supplied string without bounds checking by
using strcpy() instead of strncpy().  If you run this program you will get a
segmentation violation.  Lets see what its stack looks when we call function:


bottom of                                                            top of
memory                                                               memory
                  buffer            sfp   ret   *str
<------          [                ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   What is going on here?  Why do we get a segmentation violation?  Simple.
strcpy() is coping the contents of *str (larger_string[]) into buffer[]
until a null character is found on the string.  As we can see buffer[] is
much smaller than *str.  buffer[] is 16 bytes long, and we are trying to stuff
it with 256 bytes.  This means that all 250 bytes after buffer in the stack
are being overwritten.  This includes the SFP, RET, and even *str!  We had 
filled large_string with the character 'A'.  It's hex character value
is 0x41.  That means that the return address is now 0x41414141.  This is
outside of the process address space.  That is why when the function returns
and tries to read the next instruction from that address you get a 
segmentation violation.

   So a buffer overflow allows us to change the return address of a function.
In this way we can change the flow of execution of the program.  Lets go back
to our first example and recall what the stack looked like:


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   Lets try to modify our first example so that it overwrites the return
address, and demonstrate how we can make it execute arbitrary code.  Just
before buffer1[] on the stack is SFP, and before it, the return address.
That is 4 bytes pass the end of buffer1[].  But remember that buffer1[] is
really 2 word so its 8 bytes long.  So the return address is 12 bytes from
the start of buffer1[].  We'll modify the return value in such a way that the
assignment statement 'x = 1;' after the function call will be jumped.  To do
so we add 8 bytes to the return address.  Our code is now:

example3.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
   int *ret;

   ret = buffer1 + 12;
   (*ret) += 8;
}

void main() {
  int x;

  x = 0;
  function(1,2,3);
  x = 1;
  printf("%d\n",x);
}
------------------------------------------------------------------------------

   What we have done is add 12 to buffer1[]'s address.  This new address is
where the return address is stored.  We want to skip pass the assignment to
the printf call.  How did we know to add 8 to the return address?  We used a
test value first (for example 1), compiled the program, and then started gdb:

------------------------------------------------------------------------------
[aleph1]$ gdb example3
GDB is free software and you are welcome to distribute copies of it
 under certain conditions; type "show copying" to see the conditions.
There is absolutely no warranty for GDB; type "show warranty" for details.
GDB 4.15 (i586-unknown-linux), Copyright 1995 Free Software Foundation, Inc...
(no debugging symbols found)...
(gdb) disassemble main
Dump of assembler code for function main:
0x8000490 <main>:       pushl  %ebp
0x8000491 <main+1>:     movl   %esp,%ebp
0x8000493 <main+3>:     subl   $0x4,%esp
0x8000496 <main+6>:     movl   $0x0,0xfffffffc(%ebp)
0x800049d <main+13>:    pushl  $0x3
0x800049f <main+15>:    pushl  $0x2
0x80004a1 <main+17>:    pushl  $0x1
0x80004a3 <main+19>:    call   0x8000470 <function>
0x80004a8 <main+24>:    addl   $0xc,%esp
0x80004ab <main+27>:    movl   $0x1,0xfffffffc(%ebp)
0x80004b2 <main+34>:    movl   0xfffffffc(%ebp),%eax
0x80004b5 <main+37>:    pushl  %eax
0x80004b6 <main+38>:    pushl  $0x80004f8
0x80004bb <main+43>:    call   0x8000378 <printf>
0x80004c0 <main+48>:    addl   $0x8,%esp
0x80004c3 <main+51>:    movl   %ebp,%esp
0x80004c5 <main+53>:    popl   %ebp
0x80004c6 <main+54>:    ret
0x80004c7 <main+55>:    nop
------------------------------------------------------------------------------

   We can see that when calling function() the RET will be 0x8004a8, and we
want to jump past the assignment at 0x80004ab.  The next instruction we want
to execute is the at 0x8004b2.  A little math tells us the distance is 8
bytes.


                                  Shell Code
                                  ~~~~~~~~~~

   So now that we know that we can modify the return address and the flow of
execution, what program do we want to execute?  In most cases we'll simply
want the program to spawn a shell.  From the shell we can then issue other
commands as we wish.  But what if there is no such code in the program we
are trying to exploit?  How can we place arbitrary instruction into its
address space?  The answer is to place the code with are trying to execute in
the buffer we are overflowing, and overwrite the return address so it points
back into the buffer.  Assuming the stack starts at address 0xFF, and that S
stands for the code we want to execute the stack would then look like this:


bottom of  DDDDDDDDEEEEEEEEEEEE  EEEE  FFFF  FFFF  FFFF  FFFF     top of
memory     89ABCDEF0123456789AB  CDEF  0123  4567  89AB  CDEF     memory
           buffer                sfp   ret   a     b     c

<------   [SSSSSSSSSSSSSSSSSSSS][SSSS][0xD8][0x01][0x02][0x03]
           ^                            |
           |____________________________|
top of                                                            bottom of
stack                                                                 stack


The code to spawn a shell in C looks like:

shellcode.c
-----------------------------------------------------------------------------
#include <stdio.h>

void main() {
   char *name[2];

   name[0] = "/bin/sh";
   name[1] = NULL;
   execve(name[0], name, NULL);
}
------------------------------------------------------------------------------

   To find out what does it looks like in assembly we compile it, and start
up gdb.  Remember to use the -static flag. Otherwise the actual code the
for the execve system call will not be included.  Instead there will be a
reference to dynamic C library that would normally would be linked in at
load time.

------------------------------------------------------------------------------
[aleph1]$ gcc -o shellcode -ggdb -static shellcode.c





ANDROID SECURITY
App review before distribution -iOS: Apple manual and automated vetting; Android -  Easier to get app placed on market,Transparent automated scanning, removal via Bouncer
App isolation and protection - Sandboxing and restricted permission ;Android - Permission model ( runtime, dangerous/ normal) ,Defense against circumvention.
ANDROID CORE SECURITY FEATURES:
•	The Android Application Sandbox, isolates app data and code execution from other apps.
•	App framework with Implementations of common security functionality such as cryptography, permissions, and secure IPC.
•	Technologies like ASLR, NX, ProPolice, safe_iop, OpenBSD dlmalloc, OpenBSD calloc, and Linux mmap_min_addr to mitigate risks associated with common memory management errors.
•	An encrypted file system that can be enabled
•	User-granted permissions to restrict access to system features and user data.
•	Application-defined permissions to control application data on a per-app basis.
THREATS TO MOBILE APPLICATIONS:
•	Privacy: Data leakage, identifier leakage, third-party tags and libraries, location privacy
•	Security: Phishing, malware & drive-bys, malicious intents on Android, Ikee/Zitmo and other mobile malware.
OWASP Mobile Top Ten:
M1This category covers misuse of a platform feature or failure to use platform security controls. It might include Android intents, platform permissions, misuse of TouchID, the Keychain, or some other security control that is part of the mobile operating system. There are several ways that mobile apps can experience this risk.
M2: This new category is a combination of M2 + M4 from Mobile Top Ten 2014. This covers insecure data storage and unintended data leakage.
M3: This covers poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
M4: This category captures notions of authenticating the end user or bad session management. This can include:
Failing to identify the user at all when that should be required
Failure to maintain the user's identity when it is required
Weaknesses in session management
M5: Insufficient Cryptography : wrong crypto usage 
M6: Insecure Authorization
M7: Client Code Quality Issues : client side eg buffer overflows 
M8: Code Tampering : attacker nodification (code, memory etc) 
M9: Reverse Engineering : by attacker and gaining info 
M10: Extraneous Functionality : hidden back door or password in comment by mistake etc .
•	M1: misuse of a platform feature or failure to use platform security controls. egAndroid intents, platform permissions, misuse of TouchID, the Keychain, or some other security control 
•	M2: covers insecure data storage and unintended data leakage.
•	M3: poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
•	M4: authenticating end user or bad session management. This can include:Failing to identify the user at all when that should be required, Failure to maintain the user's identity when it is required. Weaknesses in session management.
MOBILE MALWARE EXAMPLES:
•	DroidDream (Android)
o	Over 58 apps uploaded to Google app market
o	Conducts data theft; send credentials to attacker
o	Trozan, gained root access
•	Ikee (iOS)
o	Worm capabilities (targeted default ssh pwd)
o	Worked only on jailbroken phones with ssh installed 
o	Zitmo (Symbian,BlackBerry,Windows,Android)
o	Propagates via SMS; claims to install a “security certificate”
o	Captures info from SMS; aimed at defeating 2-factor auth 
o	Works with Zeus botnet; timed with user PC infection.
COMPARISON BETWEEN PLATFORMS: 
•	Approval process for applications
o	Market: Vendor controlled/Open
o	App signing: Vendor-issued/self-signed
o	User approval of permission
•	Programming language for applications
o	Managed execution: Java, .Net 
o	Native execution: Objective C0.
ANDROID:
•	Platform outline:
o	Linux kernel, browser, SQL-lite database
o	Software for secure network communication
	Open SSL, Bouncy Castle crypto API and Java library 
o	C language infrastructure
o	Java platform for running applications
	Dalvik bytecode, virtual machine
                              ,         

ANDROID MARKET:
•	Self-signed apps
•	App permissions granted on user installation
•	Open market -  Bad applications may show up on market;Shifts focus from remote exploit to privilege escalation.
ANDROID PERMISSIONS:
•	Example of permissions provided by Android
o	“android.permission.INTERNET”
o	“android.permission.READ_EXTERNAL_STORAGE 
o	“android.permission.SEND_SMS”
o	“android.permission.BLUETOOTH” 
•	Also possible to define custom permissions
ANDROID PERMISSION MODEL:
Google maps or Uber asking for location permission to be switched on.
 
 
SECURITY FEATURES:
•	Isolation
o	Multi-user Linux operating system 
o	Each application normally runs as a different user
•	Communication between applications
o	May share same Linux user ID
	Access files from each other
	May share same Linux process and Dalvik VM
o	Communicate through application framework
	“Intents,” based on Binder, discussed in a few slides
•	Battery life
o	Developers must conserve power
o	Applications store state so they can be stopped (to save power) and restarted.
APPLICATION  SANDBOX:
o	Each application runs with its UID in its own Dalvik virtual machine
	Provides CPU protection, memory protection
	Authenticated communication protection using Unix domain sockets
	Only ping, zygote (spawn another process) run as root
o	Applications announce permission requirement
	Create a whitelist model – user grants access
	Don’t interrupt user  – all questions asked as install time
	Inter-component communication reference monitor checks permissions.
EXPLOIT PREVENTION:
	Open source: public review, no obscurity
	Goals
o	Prevent remote attacks, privilege escalation
o	Secure drivers, media codecs, new and custom features
	Overflow prevention
o	ProPolice stack protection
	First on the ARM architecture
o	Some heap overflow protections
	Chunk consolidation in DL malloc (from OpenBSD)
	ASLR (Address Space Layout Randomisation) 
o	Avoided in initial release
	Many pre-linked images for performance 
o	Later developed and contributed by Bojinov, Boneh.
DLMALLOC: 
	Stores meta data in band 
	Heap consolidation attack
o	Heap overflow can overwrite pointers to previous and next unconsolidated chunks
o	Overwriting these pointers allows remote code execution
	Change to improve security
o	Check integrity of forward and backward pointers
	Simply check that back-forward-back = back,  f-b-f=f
o	Increases the difficulty of heap overflow
APPLICATION DEVELOPMENT CONCEPTS:
	Activity – one-user task
o	Example: scroll through your inbox
o	Email client comprises many activities
	Service – Java daemon that runs in background
o	Example: application that streams an mp3 in background
	Intents – asynchronous messaging system
o	Fire an intent to switch from one activity to another
o	Example: email app has inbox, compose activity, viewer activity
	User click on inbox entry fires an intent to the viewer activity, which then allows user to view that email
	Content provider
o	Store and share data using a relational database interface 
	Broadcast receiver
o	 “mailboxes” for messages from other applications
ANDROID INTENTS: 
	Message between components in same or different app
	Intent is a bundle of information, e.g.,  
o	action to be taken
o	data to act on
o	category of component to handle the intent
o	instructions on how to launch a target activity
	Routing can be
o	Explicit: delivered only to a specific receiver 
o	Implicit: all components that have registered to receive that action will get the message
 
 
SECURITY ISSUES WITH INTENTS:
	Sender of an intent can verify that the recipient has a permission by specifying a permission with the method call
	Senders can use explicit intents to send the message to a single component (avoiding broadcasting)
	Receivers have to handle malicious intents
ATTACK : PERMISSION REDELEGATION
	Definition: an application without a permission gains additional privileges through another application 
	Example of the “confused deputy” problem 
   
	App w/ permissions exposes a public interface
	Study in 2011
o	Examine 872 apps
o	320 of these (37%) have permissions and at least one type of public component
o	Construct attacks using 15 vulnerabilities in 5 apps
POWER CONTROL WIDGET:
	Can change Wi-fi, BT, GPS, Data Sync, Screen Brightness with only one click 
	Uses Intent to communicate the event of switching settings
A malicious app without permissions can send a fake Intent to the Power Control Widget, simulating click to switch settings
Principle of least privilege works but is not a solution. Apps with permissions need to manage security.
JAVA SANDBOX:
	Four complementary mechanisms
o	Class loader
	Separate namespaces for separate class loaders
	Associates protection domain with each class 
o	Verifier and JVM run-time tests
	NO unchecked casts or other type errors, NO array overflow
	Preserves private, protected visibility levels
o	Security Manager
	Called by library functions to decide if request is allowed
	Uses protection domain associated with code, user policy
STACK INSPECTION: 
•	Permission depends on
o	Permission of calling method
o	Permission of all methods above it on stack
	Up to method that is trusted and asserts this trust 
MAC OS APPLICATION DEVELOPMENT:
•	Apps developed in Objective-C using Apple SDK
•	model based on touch events
•	FoundEvent-handling ation and UIKit frameworks provide the key services used by all iOS applications



MAC OS PLATFORM:
 

 

APP SECURITY:
•	Runtime protection
o	System resources, kernel shielded from user apps
o	App “sandbox” prevents access to other app’s data 
o	Inter-app communication only through iOS APIs 
o	Code generation prevented
•	Mandatory code signing
o	All apps must be signed using Apple-issued certificate
•	Application data protection
o	Apps can leverage built-in hardware encryption
IOS SANDBOX:
•	Limit app’s access to files, preferences, network, other resources
•	Each app has own sandbox directory
•	Limits consequences of attacks
•	Same privileges for each app
FILE ENCRYPTION:
•	The content of a file is encrypted with a per-file key, which is wrapped with a class key and stored in a file’s metadata, which is in turn encrypted with the file system key. 
o	When a file is opened, its metadata is decrypted with the file system key, revealing the wrapped per-file key and a notation on which class protects it 
o	The per-file key is unwrapped with the class key, then supplied to the hardware AES engine, decrypting the file as it is read from flash memory
•	The metadata of all files is encrypted with a random key. Since it’s stored on the device, used only for quick erased on demand.
 
MASQUE ATTACK:
•	iOS app installed using enterprise/ad-hoc provisioning could replace genuine app installed through the App Store, if both apps have same bundle identifier
•	This vulnerability existed because iOS didn't enforce matching certificates for apps with the same bundle identifier 
COMPARISON OF MAC OS VS ANDROID:
•	App approval process
o	Android apps from open app store
o	iOS vendor-controlled store of vetted apps
•	Application permissions
o	Android permission based on install-time manifest
o	All iOS apps have same set of “sandbox” privileges
•	App programming language
o	Android apps written in Java; no buffer overflow…
o	iOS apps written in Objective-C
	iOS	Android	Windows
Unix	x	x	
Windows			
Open market		x	
Closed market	x		
Vendor signed	x		
Self-signed		x	
User approval of permissions		x	
Managed code		x	
Native code	x		

MOST SIGNIFICANT VULNERABILITIES:
	Loading untrusted web content
	Leaking URLs to foreign apps
	Exposing state changing navigation to foreign apps


BUFFER OVERFLOW
EXPLANATION FOR LAST PROGRAM:
Figure 11.12a illustrates such a vulnerable program (which shares many similarities with Figure 11.11a, except that the structure is declared as a global variable). The design of the attack is very similar, indeed only the target address changes. The global structure was found to be at address 0x08049740, which was used as the target address in the attack. Note that global variables do not usually change location, as their addresses are used directly in the program code. The attack script and result of successfully executing it are shown in the text in Figure 11.12b.
MALICIOUS SOFTWARE:
	programs exploiting system vulnerabilities
	known as malicious software or malware 
o	program fragments that need a host program
	e.g. viruses, logic bombs, and backdoors 
o	independent self-contained programs
	e.g. worms, bots
o	replicating or not
	sophisticated threat to computer systems

MALWARE TECHNOLOGY:
	Mobile code software : can be shipped unchanged to a heterogeneous collection of platforms and execute with identical semantics
	Auto-rooter malicious hacker tools : used to break into new machines remotely Kit (virus generator) Set of tools for generating new viruses automatically 
	Spammer and Flooder programs : used to send large volumes of unwanted e-mail, or to attack systems with a large volumes of traffic to carry out a DoS attack.
VIRUS:
	piece of software that infects programs
o	modifying them to include a copy of the virus
o	so it executes secretly when host program is run
	specific to operating system and hardware
o	taking advantage of their details and weaknesses
	a typical virus goes through phases of:
o	dormant
o	propagation
o	triggering
o	execution
Email Viruses
A more recent development in malicious software is the e-mail virus. The first rapidly spreading e-mail viruses, such as Melissa, made use of a Microsoft Word macro embedded in an attachment. If the recipient opens the e-mail attachment, the Word macro is activated. Then the e-mail virus sends itself to everyone on the mailing list in the user's e-mail package, and also does local damage.
At the end of 1999, a more powerful version of the e-mail virus appeared. This newer version can be activated merely by opening an e-mail that contains the virus rather than opening an attachment. The virus uses the Visual Basic scripting language supported by the e-mail package.
Thus we see a new generation of malware that arrives via e-mail and uses e-mail software features to replicate itself across the Internet. The virus propagates itself as soon as activated (either by opening an e-mail attachment of by opening the e-mail) to all of the e-mail addresses known to the infected host. As a result, whereas viruses used to take months or years to propagate, they now do so in hours. This makes it very difficult for antivirus software to respond before much damage is done. Ultimately, a greater degree of security must be built into Internet utility and application software on PCs to counter the growing threat.
DIGITAL IMMUNE SYSTEM:
Comprehensive approach to virus protection developed by IBM and subsequently refined by Symantec
When a new virus enters an organization, the immune system automatically captures it, analyzes it, adds detection and shielding for it, removes it, and passes information about that virus to other systems so that it can be detected before it is allowed to run elsewhere
	1. A monitoring program on each PC uses a variety of heuristics to infer that a virus may be present, and forwards a copy to an administrative machine.
	2. The admin machine encrypts this and sends it to a central virus analysis machine.
	3. This machine creates an environment in which the infected program can be safely run for analysis. The virus analysis machine then produces a prescription for identifying and removing the virus.
	 4. The resulting prescription is sent back to the administrative machine. 
	5.  The administrative machine forwards the prescription to the infected client.
	 6. The prescription is also forwarded to other clients in the organization.
	 7. Subscribers worldwide receive regular antivirus updates to protect from new virus
The success of the digital immune system depends on the ability of the virus analysis machine to detect new and innovative virus strains.

  
 
BEHAVIOURAL BLOCKING SOFTWARE:
Unlike heuristics or fingerprint-based scanners, behavior-blocking software integrates with the operating system of a host computer and monitors program behavior in real-time for malicious actions. The behavior blocking software then blocks potentially malicious actions before they can affect the system. Monitored behaviors can include
• Attempts to open, view, delete, and/or modify files;
• Attempts to format disk drives and other unrecoverable disk operations;
• Modifications to the logic of executable files or macros;
• Modification of critical system settings, such as start-up settings;
• Scripting of e-mail and instant messaging clients to send executable content; and
• Initiation of network communications.
Figure 7.5 illustrates its operation. Behavior-blocking software runs on server and desktop computers and is instructed through policies set by the network administrator to let benign actions take place but to intercede when unauthorized or suspicious actions occur. The module blocks any suspicious software from executing. A blocker isolates the code in a sandbox, which restricts the code's access to various OS resources and applications. The blocker then sends an alert. Because behavior blocker can block suspicious software in real-time, it has an advantage over such established antivirus detection techniques as fingerprinting or heuristics. Behavior blocking alone has limitations. Because the malicious code must run on the target machine before all its behaviors can be identified, it can cause harm before it has been detected and blocked. 
MORRIS WORM: Until the current generation of worms, the best known was the worm released onto the Internet by Robert Morris in 1988. The Morris worm was designed to spread on UNIX systems and used a number of different techniques for propagation. When a copy began execution, its first task was to discover other hosts known to this host that would allow entry from this host. The worm performed this task by examining a variety of lists and tables, including system tables that declared which other machines were trusted by this host, users' mail forwarding files, tables by which users gave themselves permission for access to remote accounts, and from a program that reported the status of network connections. For each discovered host, the worm tried a number of methods for gaining access:
1.	 It attempted to log on to a remote host as a legitimate user, having cracked the local password file, and assuming that many users use the same password on different systems. 
2.	 It exploited a bug in the finger protocol
3.	It exploited a trapdoor in the debug option of the remote sendmail process.
If any of these attacks succeeded, the worm achieved communication with the operating system command interpreter. It then sent this interpreter a short bootstrap program, issued a command to execute that program, and then logged off. The bootstrap program then called back the parent program and downloaded the remainder of the worm. The new worm was then executed.
WORM COUNTERMEASURES:
There is considerable overlap in techniques for dealing with viruses and worms. Once a worm is resident on a machine, antivirus software can be used to detect it. In addition, because worms propagation generates considerable network activity, the monitoring of that activity can lead form the basis of a worm defense. Have classes: 
A.	Signature-based worm scan filtering: generates a worm signature, which is then used to prevent worm scans from entering/leaving a network/host. 
B.	Filter-based worm containment: focuses on worm content rather than a scan signature. The filter checks a message to determine if it contains worm code.
C.	Payload-classification-based worm containment: examine packets to see if they contain a worm using anomaly detection techniques 
D.	Threshold random walk (TRW) scan detection: exploits randomness in picking destinations to connect to as a way of detecting if a scanner is in operation 
E.	Rate limiting: limits the rate of scanlike traffic from an infected host. 
F.	Rate halting: immediately blocks outgoing traffic when a threshold is exceeded either in outgoing connection rate or diversity of connection attempts. Rate halting can integrate with a signature- or filter-based approach so that once a signature or filter is generated, every blocked host can be unblocked; as with rate limiting, rate halting techniques are not suitable for slow, stealthy worms. 

PROACTIVE WORM CONTAINMENT:
The Proactive Worm Containment (PWC) scheme is host based software that looks for surges in the rate of frequency of outgoing connection attempts and the diversity of connections to remote hosts. When such a surge is detected, the software immediately blocks its host from further connection attempts. A deployed PWC system consists of a PWC manager and PWC agents in hosts. Figure 7.7 from the text is an example of an architecture that includes PWC, which operates as detailed: 
A.	 A PWC agent monitors outgoing traffic for scan activity, determined by a surge in UDP / TCP connection attempts to remote hosts. If a surge is detected, the agent: 1) issues an alert to local system; 2) blocks all outgoing connection attempts; 3) transmits the alert to the PWC manager; and  4) starts a relaxation analysis. 
B. A PWC manager receives an alert, and propagates the alert to all other agents.
C. The host receives an alert, and must decide whether to ignore the alert. If the time since the last incoming packet has been sufficiently long so that the agent would have detected a worm if infected, then the alert is ignored. Otherwise, the agent assumes that it might be infected and performs the following actions:(1) blocks all outgoing connection attempts from the specific alerting port;and (2) starts a relaxation analysis. 
D. Relaxation analysis. An agent monitors outgoing activity for a fixed window of time to see if outgoing connections exceed a threshold. If so, blockage is continued and relaxation analysis is repeated until the outgoing connection rate drops below the threshold, at which time the agent removes the block. If the threshold continues to be exceeded over a sufficient number of relaxation windows, the agent isolates the host and reports to the PWC manager. 
Meanwhile, a signature extractor functions as a passive sensor that monitors all traffic and attempts to detect worms by signature analysis. 

NETWORK BASED WORM DEFENSE
The key element of a network-based worm defense is worm monitoring software. Two types of monitoring software are needed: 
• Ingress monitors: located at the border between the enterprise network and the Internet, in a border router, external firewall, separate passive monitor, or honeypot.
• Egress monitors: located at the egress point of individual LANs on the enterprise network as well as at the external border, in a LAN router or switch, external firewall or honeypot. The two types of monitors can be collocated. It is designed to catch the source of a worm attack by monitoring outgoing traffic for signs of scanning etc.
Worm monitors can act in the manner of intrusion detection systems and generate alerts to a central administrative system. It is also possible to implement a system that attempts to react in real time to a worm attack, so as to counter zero-day exploits effectively. This is similar to the approach taken with the digital immune system (Figure 7.4). Figure 7.8 shows an example of a worm countermeasure architecture that works as :
1.	Sensors deployed at various network locations detect a potential worm.
2. and send alerts to a central server that correlates / analyzes incoming alerts.
3. forwards info to a protected environment, where worm is sandboxed for analysis 
4. protected system tests the suspicious software against an appropriately instrumented version of the targeted application to identify the vulnerability. 
5. protected system generates one or more software patches and tests these.
6. system sends the patch to the application host to update the targeted application. 

INTERNET SECURITY PROTOCOLS AND STANDARDS
IPSec ensures TCP and application protocol is encrypted – and much of IP too.
With SSL or TLS, IP and TCP are not encrypted.
Benefits in routing applications:
	A routing advertisement : comes from an authorised router
	A neighbour advertisement
	A redirect message comes from router to which initial message was sent
	A routing update is not forged
	An ICMP redirect is an error message sent by a router to the sender of an IP packet . Redirects are used when a router believes a packet is being routed sub optimally and it would like to inform the sending host that it should forward subsequent packets to that same destination through a different gateway.
 

 
AUTHENTICATION HEADER: The Authentication Header provides support for data integrity and authentication of IP packets.The data integrity feature ensures that undetected modification to a packet’s content in transit is not possible. The authentication feature enables an end system or network device to authenticate the user or application and filter traffic accordingly; it also prevents address spoofing attacks and replay attacks. Authentication is based on the use of a message authentication code (MAC), hence the two parties must share a secret key. AH supports MACs using HMAC-MD5-96 or HMAC-SHA-1-96. Both of these use the HMAC algorithm , the first with the MD5 hash code and the second with the SHA-1 hash code. In both cases, the full HMAC value is calculated but then truncated by using the first 96-bits, which is the default length for the Authentication Data field.
ENCAPSULATION SECURITY PAYLOAD  (ESP):
	Provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality 
	As an optional feature, ESP can also provide an authentication service, with the same MACs as AH
	Padding used based on need on encryption algorithm used, also used for limited data confidentiality by concealing actual length of flow
 
Figure 21.4 shows the Authentication Header fields:
• Next Header (8 bits): Identifies the type of header immediately following this header
• Payload Length (8 bits): Length of Authentication Header in 32-bit words, minus 2. 
• Reserved (16 bits): For future use
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value
• Authentication Data (variable): A variable-length field (must be an integral number of 32-bit words) that contains the Integrity Check Value (ICV), or MAC,for this packet
The authentication data field is calculated over
• IP header fields that either do not change in transit (immutable) or that are predictable in value upon arrival at the endpoint for the AH SA. 
• The AH header other than the Authentication Data field. The Authentication Data field is set to zero for purposes of calculation at both source and destination. 
• The entire upper-level protocol data, which is assumed to be immutable in transit.

ENCAPSULATION SECURITY PAYLOAD:

The Encapsulating Security Payload provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality. As an optional feature, ESP can also provide an authentication service, with the same MACs as AH. ESP supports range of ciphers, modes, and padding, as shown.
 Figure 21.5 shows the format of an ESP packet. It contains the following fields:
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value; this provides an anti-replay function ,as discussed for AH
• Payload Data (variable): This is a transport-level segment (transport mode) or IP packet (tunnel mode) that is protected by encryption
• Padding (0–255 bytes): for various reasons
• Pad Length (8 bits): Indicates the number of pad bytes immediately preceding this field
• Next Header (8 bits): Identifies the type of data contained in the payload data field by identifying the first header in that payload 
• Authentication Data (variable): A variable-length field that contains the Integrity Check Value computed over the ESP packet minus the Authentication Data field 
TRANSPORT VS TUNNEL MODE:
Stallings Figure 16.5 shows the difference between end-to-end (transport) mode and end-to-intermediate (tunnel) mode.
Transport mode provides protection primarily for upper-layer protocol payloads, by inserting the AH after the original IP header and before the IP payload. Typically, transport mode is used for end-to-end communication between two hosts.
Tunnel mode provides protection to the entire IP, after the AH or ESP fields are added to the IP packet, the entire packet plus security fields is treated as the payload of new “outer”IP packet with a new outer IP header. Tunnel mode is used when one or both ends of an SA are a security gateway, such as a firewall or router that implements IPSec. 


 
 

 
KEY MANAGEMENT:
The key management portion of IPSec involves the determination and distribution of secret keys. A typical requirement is four keys for communication between two applications: transmit and receive pairs for both AH and ESP. The IPSec Architecture document mandates support for two types of key management:
• Manual where a system administrator manually configures each system with its own keys and with the keys of other communicating 
• Automated where an automated system enables the on-demand creation of keys for SAs and facilitates the use of keys in a large distributed system with an evolving configuration
The default automated key management protocol for IPSec is referred to as ISAKMP/Oakley.
Default Key Management protocol for IPSEC is ISAKMP/Oakley. Following elements
	Oakley Key Determination protocol : Based on Diffie-Hellman algorithm but providing added security to avoid man in middle attack
	Internet Security Association and Key Management Protocol (ISAKMP) Framework for Internet Key management and provides specific protocol support 


PUBLIC KEY ENCRYPTION:
Main Characteristics or differentiating factors
	Digest Length
	Basic Unit of processing ( input block length )
	Number of steps
	Maximum message size
	Number of primitive logical functions
	Number of additive constants used
HMAC: In recent years, there has been increased interest in developing a MAC derived from a cryptographic hash code, such as SHA-1, since these are usually faster, and code is widely available. A hash function such as SHA-1 was not designed for use as a MAC and cannot be used directly for that purpose because it does not rely on a secret key. There have been a number of proposals for the incorporation of a secret key into an existing hash algorithm. The approach that has received the most support is HMAC. 
HMAC has been issued as RFC 2104, has been chosen as the mandatory-to-implement MAC for IP Security, and is used in other Internet protocols, such as Transport Layer Security (TLS, soon to replace Secure Sockets Layer) and Secure Electronic Transaction (SET). HMAC treats the hash function as a "black box." This has two benefits. First, an existing implementation of a hash function can be used as a module in implementing HMAC. In this way, the bulk of the HMAC code is prepackaged and ready to use without modification. Second, if it is ever desired to replace a given hash function in an HMAC implementation, all that is required is to remove the existing hash function module and drop in the new module. This could be done if a faster hash function were desired. More important, if the security of the embedded hash function were compromised, the security of HMAC could be retained simply by replacing the embedded hash function with a more secure one. Also, HMAC can be proven secure provided that the embedded hash function has some reasonable cryptographic strengths. 
CRYPTOGRAPHIC HASH FUNCTION – HMAC :
Design Objectives
	Developing MAC from Cryptographic hash code ( relies on secret key)
	To be able to use existing hash functions without modification
	Allow easy replaceability of embedded hash function in case faster or more secure functions are found
	No degradation on performance from original hash function
	Handle keys in a simple way
	Well understood analysis of strength of authentication mechanism


STACK SMASHING
             
	`Smash the stack` [C programming] n. On many C implementations
	it is possible to corrupt the execution stack by writing past
	the end of an array declared auto in a routine.  Code that does
	this is said to smash the stack, and can cause return from the
	routine to jump to a random address.  This can produce some of
	the most insidious data-dependent bugs known to mankind.
	Variants include trash the stack, scribble the stack, mangle
	the stack; the term mung the stack is not used, as this is
	never done intentionally. See spam; see also alias bug,
	fandango on core, memory leak, precedence lossage, overrun screw.

INTRODUCTION
   Over the last few months there has been a large increase of buffer
overflow vulnerabilities being both discovered and exploited.  Examples
of these are syslog, splitvt, sendmail 8.7.5, Linux/FreeBSD mount, Xt 
library, at, etc.  This paper attempts to explain what buffer overflows 
are, and how their exploits work.

   Basic knowledge of assembly is required.  An understanding of virtual 
memory concepts, and experience with gdb are very helpful but not necessary.
We also assume we are working with an Intel x86 CPU, and that the operating 
system is Linux.

   Some basic definitions before we begin: A buffer is simply a contiguous 
block of computer memory that holds multiple instances of the same data 
type.  C programmers normally associate with the word buffer arrays. Most 
commonly, character arrays.  Arrays, like all variables in C, can be 
declared either static or dynamic.  Static variables are allocated at load 
time on the data segment.  Dynamic variables are allocated at run time on 
the stack. To overflow is to flow, or fill over the top, brims, or bounds. 
We will concern ourselves only with the overflow of dynamic buffers, otherwise
known as stack-based buffer overflows.


                          Process Memory Organization
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~

   To understand what stack buffers are we must first understand how a
process is organized in memory.  Processes are divided into three regions:
Text, Data, and Stack.  We will concentrate on the stack region, but first
a small overview of the other regions is in order.

   The text region is fixed by the program and includes code (instructions)
and read-only data.  This region corresponds to the text section of the
executable file.  This region is normally marked read-only and any attempt to
write to it will result in a segmentation violation.

   The data region contains initialized and uninitialized data.  Static
variables are stored in this region.  The data region corresponds to the
data-bss sections of the executable file.  Its size can be changed with the
brk(2) system call.  If the expansion of the bss data or the user stack
exhausts available memory, the process is blocked and is rescheduled to
run again with a larger memory space. New memory is added between the data
and stack segments.

                             /------------------\  lower
                             |                  |  memory
                             |       Text       |  addresses
                             |                  |
                             |------------------|
                             |   (Initialized)  |
                             |        Data      |
                             |  (Uninitialized) |
                             |------------------|
                             |                  |
                             |       Stack      |  higher
                             |                  |  memory
                             \------------------/  addresses

                         Fig. 1 Process Memory Regions


                               What Is A Stack?
                               ~~~~~~~~~~~~~~~~

   A stack is an abstract data type frequently used in computer science.  A
stack of objects has the property that the last object placed on the stack
will be the first object removed.  This property is commonly referred to as
last in, first out queue, or a LIFO.

   Several operations are defined on stacks.  Two of the most important are
PUSH and POP.  PUSH adds an element at the top of the stack.  POP, in 
contrast, reduces the stack size by one by removing the last element at the 
top of the stack.


                            Why Do We Use A Stack?
                            ~~~~~~~~~~~~~~~~~~~~~~

   Modern computers are designed with the need of high-level languages in
mind.  The most important technique for structuring programs introduced by
high-level languages is the procedure or function.  From one point of view, a
procedure call alters the flow of control just as a jump does, but unlike a
jump, when finished performing its task, a function returns control to the 
statement or instruction following the call.  This high-level abstraction
is implemented with the help of the stack.

  The stack is also used to dynamically allocate the local variables used in
functions, to pass parameters to the functions, and to return values from the
function.


                               The Stack Region
                               ~~~~~~~~~~~~~~~~

   A stack is a contiguous block of memory containing data.  A register called
the stack pointer (SP) points to the top of the stack.  The bottom of the 
stack is at a fixed address.  Its size is dynamically adjusted by the kernel 
at run time. The CPU implements instructions to PUSH onto and POP off of the 
stack. 

   The stack consists of logical stack frames that are pushed when calling a
function and popped when returning.  A stack frame contains the parameters to 
a function, its local variables, and the data necessary to recover the 
previous stack frame, including the value of the instruction pointer at the 
time of the function call.

   Depending on the implementation the stack will either grow down (towards
lower memory addresses), or up.  In our examples we'll use a stack that grows
down.  This is the way the stack grows on many computers including the Intel, 
Motorola, SPARC and MIPS processors.  The stack pointer (SP) is also
implementation dependent.  It may point to the last address on the stack, or 
to the next free available address after the stack.  For our discussion we'll
assume it points to the last address on the stack.

   In addition to the stack pointer, which points to the top of the stack
(lowest numerical address), it is often convenient to have a frame pointer
(FP) which points to a fixed location within a frame.  Some texts also refer
to it as a local base pointer (LB).  In principle, local variables could be
referenced by giving their offsets from SP.  However, as words are pushed onto
the stack and popped from the stack, these offsets change.  Although in some
cases the compiler can keep track of the number of words on the stack and
thus correct the offsets, in some cases it cannot, and in all cases
considerable administration is required.  Futhermore, on some machines, such
as Intel-based processors, accessing a variable at a known distance from SP
requires multiple instructions.

   Consequently, many compilers use a second register, FP, for referencing
both local variables and parameters because their distances from FP do
not change with PUSHes and POPs.  On Intel CPUs, BP (EBP) is used for this 
purpose.  On the Motorola CPUs, any address register except A7 (the stack 
pointer) will do.  Because the way our stack grows, actual parameters have 
positive offsets and local variables have negative offsets from FP.

   The first thing a procedure must do when called is save the previous FP
(so it can be restored at procedure exit).  Then it copies SP into FP to 
create the new FP, and advances SP to reserve space for the local variables. 
This code is called the procedure prolog.  Upon procedure exit, the stack 
must be cleaned up again, something called the procedure epilog.  The Intel 
ENTER and LEAVE instructions and the Motorola LINK and UNLINK instructions, 
have been provided to do most of the procedure prolog and epilog work 
efficiently. 

   Let us see what the stack looks like in a simple example:

example1.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
}

void main() {
  function(1,2,3);
}
------------------------------------------------------------------------------

   To understand what the program does to call function() we compile it with
gcc using the -S switch to generate assembly code output:

$ gcc -S -o example1.s example1.c

   By looking at the assembly language output we see that the call to
function() is translated to:

        pushl $3
        pushl $2
        pushl $1
        call function

    This pushes the 3 arguments to function backwards into the stack, and
calls function().  The instruction 'call' will push the instruction pointer
(IP) onto the stack.  We'll call the saved IP the return address (RET).  The
first thing done in function is the procedure prolog:

        pushl %ebp
        movl %esp,%ebp
        subl $20,%esp

   This pushes EBP, the frame pointer, onto the stack.  It then copies the
current SP onto EBP, making it the new FP pointer.  We'll call the saved FP
pointer SFP.  It then allocates space for the local variables by subtracting
their size from SP.

   We must remember that memory can only be addressed in multiples of the
word size.  A word in our case is 4 bytes, or 32 bits.  So our 5 byte buffer
is really going to take 8 bytes (2 words) of memory, and our 10 byte buffer
is going to take 12 bytes (3 words) of memory.  That is why SP is being
subtracted by 20.  With that in mind our stack looks like this when
function() is called (each space represents a byte):


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]
	   
top of                                                            bottom of
stack                                                                 stack


                               Buffer Overflows
                               ~~~~~~~~~~~~~~~~

   A buffer overflow is the result of stuffing more data into a buffer than
it can handle.  How can this often found programming error can be taken
advantage to execute arbitrary code?  Lets look at another example:

example2.c
------------------------------------------------------------------------------
void function(char *str) {
   char buffer[16];

   strcpy(buffer,str);
}

void main() {
  char large_string[256];
  int i;

  for( i = 0; i < 255; i++)
    large_string[i] = 'A';

  function(large_string);
}
------------------------------------------------------------------------------

   This is program has a function with a typical buffer overflow coding
error.  The function copies a supplied string without bounds checking by
using strcpy() instead of strncpy().  If you run this program you will get a
segmentation violation.  Lets see what its stack looks when we call function:


bottom of                                                            top of
memory                                                               memory
                  buffer            sfp   ret   *str
<------          [                ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   What is going on here?  Why do we get a segmentation violation?  Simple.
strcpy() is coping the contents of *str (larger_string[]) into buffer[]
until a null character is found on the string.  As we can see buffer[] is
much smaller than *str.  buffer[] is 16 bytes long, and we are trying to stuff
it with 256 bytes.  This means that all 250 bytes after buffer in the stack
are being overwritten.  This includes the SFP, RET, and even *str!  We had 
filled large_string with the character 'A'.  It's hex character value
is 0x41.  That means that the return address is now 0x41414141.  This is
outside of the process address space.  That is why when the function returns
and tries to read the next instruction from that address you get a 
segmentation violation.

   So a buffer overflow allows us to change the return address of a function.
In this way we can change the flow of execution of the program.  Lets go back
to our first example and recall what the stack looked like:


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   Lets try to modify our first example so that it overwrites the return
address, and demonstrate how we can make it execute arbitrary code.  Just
before buffer1[] on the stack is SFP, and before it, the return address.
That is 4 bytes pass the end of buffer1[].  But remember that buffer1[] is
really 2 word so its 8 bytes long.  So the return address is 12 bytes from
the start of buffer1[].  We'll modify the return value in such a way that the
assignment statement 'x = 1;' after the function call will be jumped.  To do
so we add 8 bytes to the return address.  Our code is now:

example3.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
   int *ret;

   ret = buffer1 + 12;
   (*ret) += 8;
}

void main() {
  int x;

  x = 0;
  function(1,2,3);
  x = 1;
  printf("%d\n",x);
}
------------------------------------------------------------------------------

   What we have done is add 12 to buffer1[]'s address.  This new address is
where the return address is stored.  We want to skip pass the assignment to
the printf call.  How did we know to add 8 to the return address?  We used a
test value first (for example 1), compiled the program, and then started gdb:

------------------------------------------------------------------------------
[aleph1]$ gdb example3
GDB is free software and you are welcome to distribute copies of it
 under certain conditions; type "show copying" to see the conditions.
There is absolutely no warranty for GDB; type "show warranty" for details.
GDB 4.15 (i586-unknown-linux), Copyright 1995 Free Software Foundation, Inc...
(no debugging symbols found)...
(gdb) disassemble main
Dump of assembler code for function main:
0x8000490 <main>:       pushl  %ebp
0x8000491 <main+1>:     movl   %esp,%ebp
0x8000493 <main+3>:     subl   $0x4,%esp
0x8000496 <main+6>:     movl   $0x0,0xfffffffc(%ebp)
0x800049d <main+13>:    pushl  $0x3
0x800049f <main+15>:    pushl  $0x2
0x80004a1 <main+17>:    pushl  $0x1
0x80004a3 <main+19>:    call   0x8000470 <function>
0x80004a8 <main+24>:    addl   $0xc,%esp
0x80004ab <main+27>:    movl   $0x1,0xfffffffc(%ebp)
0x80004b2 <main+34>:    movl   0xfffffffc(%ebp),%eax
0x80004b5 <main+37>:    pushl  %eax
0x80004b6 <main+38>:    pushl  $0x80004f8
0x80004bb <main+43>:    call   0x8000378 <printf>
0x80004c0 <main+48>:    addl   $0x8,%esp
0x80004c3 <main+51>:    movl   %ebp,%esp
0x80004c5 <main+53>:    popl   %ebp
0x80004c6 <main+54>:    ret
0x80004c7 <main+55>:    nop
------------------------------------------------------------------------------

   We can see that when calling function() the RET will be 0x8004a8, and we
want to jump past the assignment at 0x80004ab.  The next instruction we want
to execute is the at 0x8004b2.  A little math tells us the distance is 8
bytes.


                                  Shell Code
                                  ~~~~~~~~~~

   So now that we know that we can modify the return address and the flow of
execution, what program do we want to execute?  In most cases we'll simply
want the program to spawn a shell.  From the shell we can then issue other
commands as we wish.  But what if there is no such code in the program we
are trying to exploit?  How can we place arbitrary instruction into its
address space?  The answer is to place the code with are trying to execute in
the buffer we are overflowing, and overwrite the return address so it points
back into the buffer.  Assuming the stack starts at address 0xFF, and that S
stands for the code we want to execute the stack would then look like this:


bottom of  DDDDDDDDEEEEEEEEEEEE  EEEE  FFFF  FFFF  FFFF  FFFF     top of
memory     89ABCDEF0123456789AB  CDEF  0123  4567  89AB  CDEF     memory
           buffer                sfp   ret   a     b     c

<------   [SSSSSSSSSSSSSSSSSSSS][SSSS][0xD8][0x01][0x02][0x03]
           ^                            |
           |____________________________|
top of                                                            bottom of
stack                                                                 stack


The code to spawn a shell in C looks like:

shellcode.c
-----------------------------------------------------------------------------
#include <stdio.h>

void main() {
   char *name[2];

   name[0] = "/bin/sh";
   name[1] = NULL;
   execve(name[0], name, NULL);
}
------------------------------------------------------------------------------

   To find out what does it looks like in assembly we compile it, and start
up gdb.  Remember to use the -static flag. Otherwise the actual code the
for the execve system call will not be included.  Instead there will be a
reference to dynamic C library that would normally would be linked in at
load time.

------------------------------------------------------------------------------
[aleph1]$ gcc -o shellcode -ggdb -static shellcode.c





ANDROID SECURITY
App review before distribution -iOS: Apple manual and automated vetting; Android -  Easier to get app placed on market,Transparent automated scanning, removal via Bouncer
App isolation and protection - Sandboxing and restricted permission ;Android - Permission model ( runtime, dangerous/ normal) ,Defense against circumvention.
ANDROID CORE SECURITY FEATURES:
•	The Android Application Sandbox, isolates app data and code execution from other apps.
•	App framework with Implementations of common security functionality such as cryptography, permissions, and secure IPC.
•	Technologies like ASLR, NX, ProPolice, safe_iop, OpenBSD dlmalloc, OpenBSD calloc, and Linux mmap_min_addr to mitigate risks associated with common memory management errors.
•	An encrypted file system that can be enabled
•	User-granted permissions to restrict access to system features and user data.
•	Application-defined permissions to control application data on a per-app basis.
THREATS TO MOBILE APPLICATIONS:
•	Privacy: Data leakage, identifier leakage, third-party tags and libraries, location privacy
•	Security: Phishing, malware & drive-bys, malicious intents on Android, Ikee/Zitmo and other mobile malware.
OWASP Mobile Top Ten:
M1This category covers misuse of a platform feature or failure to use platform security controls. It might include Android intents, platform permissions, misuse of TouchID, the Keychain, or some other security control that is part of the mobile operating system. There are several ways that mobile apps can experience this risk.
M2: This new category is a combination of M2 + M4 from Mobile Top Ten 2014. This covers insecure data storage and unintended data leakage.
M3: This covers poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
M4: This category captures notions of authenticating the end user or bad session management. This can include:
Failing to identify the user at all when that should be required
Failure to maintain the user's identity when it is required
Weaknesses in session management
M5: Insufficient Cryptography : wrong crypto usage 
M6: Insecure Authorization
M7: Client Code Quality Issues : client side eg buffer overflows 
M8: Code Tampering : attacker nodification (code, memory etc) 
M9: Reverse Engineering : by attacker and gaining info 
M10: Extraneous Functionality : hidden back door or password in comment by mistake etc .
•	M1: misuse of a platform feature or failure to use platform security controls. egAndroid intents, platform permissions, misuse of TouchID, the Keychain, or some other security control 
•	M2: covers insecure data storage and unintended data leakage.
•	M3: poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
•	M4: authenticating end user or bad session management. This can include:Failing to identify the user at all when that should be required, Failure to maintain the user's identity when it is required. Weaknesses in session management.
MOBILE MALWARE EXAMPLES:
•	DroidDream (Android)
o	Over 58 apps uploaded to Google app market
o	Conducts data theft; send credentials to attacker
o	Trozan, gained root access
•	Ikee (iOS)
o	Worm capabilities (targeted default ssh pwd)
o	Worked only on jailbroken phones with ssh installed 
o	Zitmo (Symbian,BlackBerry,Windows,Android)
o	Propagates via SMS; claims to install a “security certificate”
o	Captures info from SMS; aimed at defeating 2-factor auth 
o	Works with Zeus botnet; timed with user PC infection.
COMPARISON BETWEEN PLATFORMS: 
•	Approval process for applications
o	Market: Vendor controlled/Open
o	App signing: Vendor-issued/self-signed
o	User approval of permission
•	Programming language for applications
o	Managed execution: Java, .Net 
o	Native execution: Objective C0.
ANDROID:
•	Platform outline:
o	Linux kernel, browser, SQL-lite database
o	Software for secure network communication
	Open SSL, Bouncy Castle crypto API and Java library 
o	C language infrastructure
o	Java platform for running applications
	Dalvik bytecode, virtual machine
                              ,         

ANDROID MARKET:
•	Self-signed apps
•	App permissions granted on user installation
•	Open market -  Bad applications may show up on market;Shifts focus from remote exploit to privilege escalation.
ANDROID PERMISSIONS:
•	Example of permissions provided by Android
o	“android.permission.INTERNET”
o	“android.permission.READ_EXTERNAL_STORAGE 
o	“android.permission.SEND_SMS”
o	“android.permission.BLUETOOTH” 
•	Also possible to define custom permissions
ANDROID PERMISSION MODEL:
Google maps or Uber asking for location permission to be switched on.
 
 
SECURITY FEATURES:
•	Isolation
o	Multi-user Linux operating system 
o	Each application normally runs as a different user
•	Communication between applications
o	May share same Linux user ID
	Access files from each other
	May share same Linux process and Dalvik VM
o	Communicate through application framework
	“Intents,” based on Binder, discussed in a few slides
•	Battery life
o	Developers must conserve power
o	Applications store state so they can be stopped (to save power) and restarted.
APPLICATION  SANDBOX:
o	Each application runs with its UID in its own Dalvik virtual machine
	Provides CPU protection, memory protection
	Authenticated communication protection using Unix domain sockets
	Only ping, zygote (spawn another process) run as root
o	Applications announce permission requirement
	Create a whitelist model – user grants access
	Don’t interrupt user  – all questions asked as install time
	Inter-component communication reference monitor checks permissions.
EXPLOIT PREVENTION:
	Open source: public review, no obscurity
	Goals
o	Prevent remote attacks, privilege escalation
o	Secure drivers, media codecs, new and custom features
	Overflow prevention
o	ProPolice stack protection
	First on the ARM architecture
o	Some heap overflow protections
	Chunk consolidation in DL malloc (from OpenBSD)
	ASLR (Address Space Layout Randomisation) 
o	Avoided in initial release
	Many pre-linked images for performance 
o	Later developed and contributed by Bojinov, Boneh.
DLMALLOC: 
	Stores meta data in band 
	Heap consolidation attack
o	Heap overflow can overwrite pointers to previous and next unconsolidated chunks
o	Overwriting these pointers allows remote code execution
	Change to improve security
o	Check integrity of forward and backward pointers
	Simply check that back-forward-back = back,  f-b-f=f
o	Increases the difficulty of heap overflow
APPLICATION DEVELOPMENT CONCEPTS:
	Activity – one-user task
o	Example: scroll through your inbox
o	Email client comprises many activities
	Service – Java daemon that runs in background
o	Example: application that streams an mp3 in background
	Intents – asynchronous messaging system
o	Fire an intent to switch from one activity to another
o	Example: email app has inbox, compose activity, viewer activity
	User click on inbox entry fires an intent to the viewer activity, which then allows user to view that email
	Content provider
o	Store and share data using a relational database interface 
	Broadcast receiver
o	 “mailboxes” for messages from other applications
ANDROID INTENTS: 
	Message between components in same or different app
	Intent is a bundle of information, e.g.,  
o	action to be taken
o	data to act on
o	category of component to handle the intent
o	instructions on how to launch a target activity
	Routing can be
o	Explicit: delivered only to a specific receiver 
o	Implicit: all components that have registered to receive that action will get the message
 
 
SECURITY ISSUES WITH INTENTS:
	Sender of an intent can verify that the recipient has a permission by specifying a permission with the method call
	Senders can use explicit intents to send the message to a single component (avoiding broadcasting)
	Receivers have to handle malicious intents
ATTACK : PERMISSION REDELEGATION
	Definition: an application without a permission gains additional privileges through another application 
	Example of the “confused deputy” problem 
   
	App w/ permissions exposes a public interface
	Study in 2011
o	Examine 872 apps
o	320 of these (37%) have permissions and at least one type of public component
o	Construct attacks using 15 vulnerabilities in 5 apps
POWER CONTROL WIDGET:
	Can change Wi-fi, BT, GPS, Data Sync, Screen Brightness with only one click 
	Uses Intent to communicate the event of switching settings
A malicious app without permissions can send a fake Intent to the Power Control Widget, simulating click to switch settings
Principle of least privilege works but is not a solution. Apps with permissions need to manage security.
JAVA SANDBOX:
	Four complementary mechanisms
o	Class loader
	Separate namespaces for separate class loaders
	Associates protection domain with each class 
o	Verifier and JVM run-time tests
	NO unchecked casts or other type errors, NO array overflow
	Preserves private, protected visibility levels
o	Security Manager
	Called by library functions to decide if request is allowed
	Uses protection domain associated with code, user policy
STACK INSPECTION: 
•	Permission depends on
o	Permission of calling method
o	Permission of all methods above it on stack
	Up to method that is trusted and asserts this trust 
MAC OS APPLICATION DEVELOPMENT:
•	Apps developed in Objective-C using Apple SDK
•	model based on touch events
•	FoundEvent-handling ation and UIKit frameworks provide the key services used by all iOS applications



MAC OS PLATFORM:
 

 

APP SECURITY:
•	Runtime protection
o	System resources, kernel shielded from user apps
o	App “sandbox” prevents access to other app’s data 
o	Inter-app communication only through iOS APIs 
o	Code generation prevented
•	Mandatory code signing
o	All apps must be signed using Apple-issued certificate
•	Application data protection
o	Apps can leverage built-in hardware encryption
IOS SANDBOX:
•	Limit app’s access to files, preferences, network, other resources
•	Each app has own sandbox directory
•	Limits consequences of attacks
•	Same privileges for each app
FILE ENCRYPTION:
•	The content of a file is encrypted with a per-file key, which is wrapped with a class key and stored in a file’s metadata, which is in turn encrypted with the file system key. 
o	When a file is opened, its metadata is decrypted with the file system key, revealing the wrapped per-file key and a notation on which class protects it 
o	The per-file key is unwrapped with the class key, then supplied to the hardware AES engine, decrypting the file as it is read from flash memory
•	The metadata of all files is encrypted with a random key. Since it’s stored on the device, used only for quick erased on demand.
 
MASQUE ATTACK:
•	iOS app installed using enterprise/ad-hoc provisioning could replace genuine app installed through the App Store, if both apps have same bundle identifier
•	This vulnerability existed because iOS didn't enforce matching certificates for apps with the same bundle identifier 
COMPARISON OF MAC OS VS ANDROID:
•	App approval process
o	Android apps from open app store
o	iOS vendor-controlled store of vetted apps
•	Application permissions
o	Android permission based on install-time manifest
o	All iOS apps have same set of “sandbox” privileges
•	App programming language
o	Android apps written in Java; no buffer overflow…
o	iOS apps written in Objective-C
	iOS	Android	Windows
Unix	x	x	
Windows			
Open market		x	
Closed market	x		
Vendor signed	x		
Self-signed		x	
User approval of permissions		x	
Managed code		x	
Native code	x		

MOST SIGNIFICANT VULNERABILITIES:
	Loading untrusted web content
	Leaking URLs to foreign apps
	Exposing state changing navigation to foreign apps


BUFFER OVERFLOW
EXPLANATION FOR LAST PROGRAM:
Figure 11.12a illustrates such a vulnerable program (which shares many similarities with Figure 11.11a, except that the structure is declared as a global variable). The design of the attack is very similar, indeed only the target address changes. The global structure was found to be at address 0x08049740, which was used as the target address in the attack. Note that global variables do not usually change location, as their addresses are used directly in the program code. The attack script and result of successfully executing it are shown in the text in Figure 11.12b.
MALICIOUS SOFTWARE:
	programs exploiting system vulnerabilities
	known as malicious software or malware 
o	program fragments that need a host program
	e.g. viruses, logic bombs, and backdoors 
o	independent self-contained programs
	e.g. worms, bots
o	replicating or not
	sophisticated threat to computer systems

MALWARE TECHNOLOGY:
	Mobile code software : can be shipped unchanged to a heterogeneous collection of platforms and execute with identical semantics
	Auto-rooter malicious hacker tools : used to break into new machines remotely Kit (virus generator) Set of tools for generating new viruses automatically 
	Spammer and Flooder programs : used to send large volumes of unwanted e-mail, or to attack systems with a large volumes of traffic to carry out a DoS attack.
VIRUS:
	piece of software that infects programs
o	modifying them to include a copy of the virus
o	so it executes secretly when host program is run
	specific to operating system and hardware
o	taking advantage of their details and weaknesses
	a typical virus goes through phases of:
o	dormant
o	propagation
o	triggering
o	execution
Email Viruses
A more recent development in malicious software is the e-mail virus. The first rapidly spreading e-mail viruses, such as Melissa, made use of a Microsoft Word macro embedded in an attachment. If the recipient opens the e-mail attachment, the Word macro is activated. Then the e-mail virus sends itself to everyone on the mailing list in the user's e-mail package, and also does local damage.
At the end of 1999, a more powerful version of the e-mail virus appeared. This newer version can be activated merely by opening an e-mail that contains the virus rather than opening an attachment. The virus uses the Visual Basic scripting language supported by the e-mail package.
Thus we see a new generation of malware that arrives via e-mail and uses e-mail software features to replicate itself across the Internet. The virus propagates itself as soon as activated (either by opening an e-mail attachment of by opening the e-mail) to all of the e-mail addresses known to the infected host. As a result, whereas viruses used to take months or years to propagate, they now do so in hours. This makes it very difficult for antivirus software to respond before much damage is done. Ultimately, a greater degree of security must be built into Internet utility and application software on PCs to counter the growing threat.
DIGITAL IMMUNE SYSTEM:
Comprehensive approach to virus protection developed by IBM and subsequently refined by Symantec
When a new virus enters an organization, the immune system automatically captures it, analyzes it, adds detection and shielding for it, removes it, and passes information about that virus to other systems so that it can be detected before it is allowed to run elsewhere
	1. A monitoring program on each PC uses a variety of heuristics to infer that a virus may be present, and forwards a copy to an administrative machine.
	2. The admin machine encrypts this and sends it to a central virus analysis machine.
	3. This machine creates an environment in which the infected program can be safely run for analysis. The virus analysis machine then produces a prescription for identifying and removing the virus.
	 4. The resulting prescription is sent back to the administrative machine. 
	5.  The administrative machine forwards the prescription to the infected client.
	 6. The prescription is also forwarded to other clients in the organization.
	 7. Subscribers worldwide receive regular antivirus updates to protect from new virus
The success of the digital immune system depends on the ability of the virus analysis machine to detect new and innovative virus strains.

  
 
BEHAVIOURAL BLOCKING SOFTWARE:
Unlike heuristics or fingerprint-based scanners, behavior-blocking software integrates with the operating system of a host computer and monitors program behavior in real-time for malicious actions. The behavior blocking software then blocks potentially malicious actions before they can affect the system. Monitored behaviors can include
• Attempts to open, view, delete, and/or modify files;
• Attempts to format disk drives and other unrecoverable disk operations;
• Modifications to the logic of executable files or macros;
• Modification of critical system settings, such as start-up settings;
• Scripting of e-mail and instant messaging clients to send executable content; and
• Initiation of network communications.
Figure 7.5 illustrates its operation. Behavior-blocking software runs on server and desktop computers and is instructed through policies set by the network administrator to let benign actions take place but to intercede when unauthorized or suspicious actions occur. The module blocks any suspicious software from executing. A blocker isolates the code in a sandbox, which restricts the code's access to various OS resources and applications. The blocker then sends an alert. Because behavior blocker can block suspicious software in real-time, it has an advantage over such established antivirus detection techniques as fingerprinting or heuristics. Behavior blocking alone has limitations. Because the malicious code must run on the target machine before all its behaviors can be identified, it can cause harm before it has been detected and blocked. 
MORRIS WORM: Until the current generation of worms, the best known was the worm released onto the Internet by Robert Morris in 1988. The Morris worm was designed to spread on UNIX systems and used a number of different techniques for propagation. When a copy began execution, its first task was to discover other hosts known to this host that would allow entry from this host. The worm performed this task by examining a variety of lists and tables, including system tables that declared which other machines were trusted by this host, users' mail forwarding files, tables by which users gave themselves permission for access to remote accounts, and from a program that reported the status of network connections. For each discovered host, the worm tried a number of methods for gaining access:
1.	 It attempted to log on to a remote host as a legitimate user, having cracked the local password file, and assuming that many users use the same password on different systems. 
2.	 It exploited a bug in the finger protocol
3.	It exploited a trapdoor in the debug option of the remote sendmail process.
If any of these attacks succeeded, the worm achieved communication with the operating system command interpreter. It then sent this interpreter a short bootstrap program, issued a command to execute that program, and then logged off. The bootstrap program then called back the parent program and downloaded the remainder of the worm. The new worm was then executed.
WORM COUNTERMEASURES:
There is considerable overlap in techniques for dealing with viruses and worms. Once a worm is resident on a machine, antivirus software can be used to detect it. In addition, because worms propagation generates considerable network activity, the monitoring of that activity can lead form the basis of a worm defense. Have classes: 
A.	Signature-based worm scan filtering: generates a worm signature, which is then used to prevent worm scans from entering/leaving a network/host. 
B.	Filter-based worm containment: focuses on worm content rather than a scan signature. The filter checks a message to determine if it contains worm code.
C.	Payload-classification-based worm containment: examine packets to see if they contain a worm using anomaly detection techniques 
D.	Threshold random walk (TRW) scan detection: exploits randomness in picking destinations to connect to as a way of detecting if a scanner is in operation 
E.	Rate limiting: limits the rate of scanlike traffic from an infected host. 
F.	Rate halting: immediately blocks outgoing traffic when a threshold is exceeded either in outgoing connection rate or diversity of connection attempts. Rate halting can integrate with a signature- or filter-based approach so that once a signature or filter is generated, every blocked host can be unblocked; as with rate limiting, rate halting techniques are not suitable for slow, stealthy worms. 

PROACTIVE WORM CONTAINMENT:
The Proactive Worm Containment (PWC) scheme is host based software that looks for surges in the rate of frequency of outgoing connection attempts and the diversity of connections to remote hosts. When such a surge is detected, the software immediately blocks its host from further connection attempts. A deployed PWC system consists of a PWC manager and PWC agents in hosts. Figure 7.7 from the text is an example of an architecture that includes PWC, which operates as detailed: 
A.	 A PWC agent monitors outgoing traffic for scan activity, determined by a surge in UDP / TCP connection attempts to remote hosts. If a surge is detected, the agent: 1) issues an alert to local system; 2) blocks all outgoing connection attempts; 3) transmits the alert to the PWC manager; and  4) starts a relaxation analysis. 
B. A PWC manager receives an alert, and propagates the alert to all other agents.
C. The host receives an alert, and must decide whether to ignore the alert. If the time since the last incoming packet has been sufficiently long so that the agent would have detected a worm if infected, then the alert is ignored. Otherwise, the agent assumes that it might be infected and performs the following actions:(1) blocks all outgoing connection attempts from the specific alerting port;and (2) starts a relaxation analysis. 
D. Relaxation analysis. An agent monitors outgoing activity for a fixed window of time to see if outgoing connections exceed a threshold. If so, blockage is continued and relaxation analysis is repeated until the outgoing connection rate drops below the threshold, at which time the agent removes the block. If the threshold continues to be exceeded over a sufficient number of relaxation windows, the agent isolates the host and reports to the PWC manager. 
Meanwhile, a signature extractor functions as a passive sensor that monitors all traffic and attempts to detect worms by signature analysis. 

NETWORK BASED WORM DEFENSE
The key element of a network-based worm defense is worm monitoring software. Two types of monitoring software are needed: 
• Ingress monitors: located at the border between the enterprise network and the Internet, in a border router, external firewall, separate passive monitor, or honeypot.
• Egress monitors: located at the egress point of individual LANs on the enterprise network as well as at the external border, in a LAN router or switch, external firewall or honeypot. The two types of monitors can be collocated. It is designed to catch the source of a worm attack by monitoring outgoing traffic for signs of scanning etc.
Worm monitors can act in the manner of intrusion detection systems and generate alerts to a central administrative system. It is also possible to implement a system that attempts to react in real time to a worm attack, so as to counter zero-day exploits effectively. This is similar to the approach taken with the digital immune system (Figure 7.4). Figure 7.8 shows an example of a worm countermeasure architecture that works as :
1.	Sensors deployed at various network locations detect a potential worm.
2. and send alerts to a central server that correlates / analyzes incoming alerts.
3. forwards info to a protected environment, where worm is sandboxed for analysis 
4. protected system tests the suspicious software against an appropriately instrumented version of the targeted application to identify the vulnerability. 
5. protected system generates one or more software patches and tests these.
6. system sends the patch to the application host to update the targeted application. 

INTERNET SECURITY PROTOCOLS AND STANDARDS
IPSec ensures TCP and application protocol is encrypted – and much of IP too.
With SSL or TLS, IP and TCP are not encrypted.
Benefits in routing applications:
	A routing advertisement : comes from an authorised router
	A neighbour advertisement
	A redirect message comes from router to which initial message was sent
	A routing update is not forged
	An ICMP redirect is an error message sent by a router to the sender of an IP packet . Redirects are used when a router believes a packet is being routed sub optimally and it would like to inform the sending host that it should forward subsequent packets to that same destination through a different gateway.
 

 
AUTHENTICATION HEADER: The Authentication Header provides support for data integrity and authentication of IP packets.The data integrity feature ensures that undetected modification to a packet’s content in transit is not possible. The authentication feature enables an end system or network device to authenticate the user or application and filter traffic accordingly; it also prevents address spoofing attacks and replay attacks. Authentication is based on the use of a message authentication code (MAC), hence the two parties must share a secret key. AH supports MACs using HMAC-MD5-96 or HMAC-SHA-1-96. Both of these use the HMAC algorithm , the first with the MD5 hash code and the second with the SHA-1 hash code. In both cases, the full HMAC value is calculated but then truncated by using the first 96-bits, which is the default length for the Authentication Data field.
ENCAPSULATION SECURITY PAYLOAD  (ESP):
	Provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality 
	As an optional feature, ESP can also provide an authentication service, with the same MACs as AH
	Padding used based on need on encryption algorithm used, also used for limited data confidentiality by concealing actual length of flow
 
Figure 21.4 shows the Authentication Header fields:
• Next Header (8 bits): Identifies the type of header immediately following this header
• Payload Length (8 bits): Length of Authentication Header in 32-bit words, minus 2. 
• Reserved (16 bits): For future use
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value
• Authentication Data (variable): A variable-length field (must be an integral number of 32-bit words) that contains the Integrity Check Value (ICV), or MAC,for this packet
The authentication data field is calculated over
• IP header fields that either do not change in transit (immutable) or that are predictable in value upon arrival at the endpoint for the AH SA. 
• The AH header other than the Authentication Data field. The Authentication Data field is set to zero for purposes of calculation at both source and destination. 
• The entire upper-level protocol data, which is assumed to be immutable in transit.

ENCAPSULATION SECURITY PAYLOAD:

The Encapsulating Security Payload provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality. As an optional feature, ESP can also provide an authentication service, with the same MACs as AH. ESP supports range of ciphers, modes, and padding, as shown.
 Figure 21.5 shows the format of an ESP packet. It contains the following fields:
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value; this provides an anti-replay function ,as discussed for AH
• Payload Data (variable): This is a transport-level segment (transport mode) or IP packet (tunnel mode) that is protected by encryption
• Padding (0–255 bytes): for various reasons
• Pad Length (8 bits): Indicates the number of pad bytes immediately preceding this field
• Next Header (8 bits): Identifies the type of data contained in the payload data field by identifying the first header in that payload 
• Authentication Data (variable): A variable-length field that contains the Integrity Check Value computed over the ESP packet minus the Authentication Data field 
TRANSPORT VS TUNNEL MODE:
Stallings Figure 16.5 shows the difference between end-to-end (transport) mode and end-to-intermediate (tunnel) mode.
Transport mode provides protection primarily for upper-layer protocol payloads, by inserting the AH after the original IP header and before the IP payload. Typically, transport mode is used for end-to-end communication between two hosts.
Tunnel mode provides protection to the entire IP, after the AH or ESP fields are added to the IP packet, the entire packet plus security fields is treated as the payload of new “outer”IP packet with a new outer IP header. Tunnel mode is used when one or both ends of an SA are a security gateway, such as a firewall or router that implements IPSec. 


 
 

 
KEY MANAGEMENT:
The key management portion of IPSec involves the determination and distribution of secret keys. A typical requirement is four keys for communication between two applications: transmit and receive pairs for both AH and ESP. The IPSec Architecture document mandates support for two types of key management:
• Manual where a system administrator manually configures each system with its own keys and with the keys of other communicating 
• Automated where an automated system enables the on-demand creation of keys for SAs and facilitates the use of keys in a large distributed system with an evolving configuration
The default automated key management protocol for IPSec is referred to as ISAKMP/Oakley.
Default Key Management protocol for IPSEC is ISAKMP/Oakley. Following elements
	Oakley Key Determination protocol : Based on Diffie-Hellman algorithm but providing added security to avoid man in middle attack
	Internet Security Association and Key Management Protocol (ISAKMP) Framework for Internet Key management and provides specific protocol support 


PUBLIC KEY ENCRYPTION:
Main Characteristics or differentiating factors
	Digest Length
	Basic Unit of processing ( input block length )
	Number of steps
	Maximum message size
	Number of primitive logical functions
	Number of additive constants used
HMAC: In recent years, there has been increased interest in developing a MAC derived from a cryptographic hash code, such as SHA-1, since these are usually faster, and code is widely available. A hash function such as SHA-1 was not designed for use as a MAC and cannot be used directly for that purpose because it does not rely on a secret key. There have been a number of proposals for the incorporation of a secret key into an existing hash algorithm. The approach that has received the most support is HMAC. 
HMAC has been issued as RFC 2104, has been chosen as the mandatory-to-implement MAC for IP Security, and is used in other Internet protocols, such as Transport Layer Security (TLS, soon to replace Secure Sockets Layer) and Secure Electronic Transaction (SET). HMAC treats the hash function as a "black box." This has two benefits. First, an existing implementation of a hash function can be used as a module in implementing HMAC. In this way, the bulk of the HMAC code is prepackaged and ready to use without modification. Second, if it is ever desired to replace a given hash function in an HMAC implementation, all that is required is to remove the existing hash function module and drop in the new module. This could be done if a faster hash function were desired. More important, if the security of the embedded hash function were compromised, the security of HMAC could be retained simply by replacing the embedded hash function with a more secure one. Also, HMAC can be proven secure provided that the embedded hash function has some reasonable cryptographic strengths. 
CRYPTOGRAPHIC HASH FUNCTION – HMAC :
Design Objectives
	Developing MAC from Cryptographic hash code ( relies on secret key)
	To be able to use existing hash functions without modification
	Allow easy replaceability of embedded hash function in case faster or more secure functions are found
	No degradation on performance from original hash function
	Handle keys in a simple way
	Well understood analysis of strength of authentication mechanism


STACK SMASHING
             
	`Smash the stack` [C programming] n. On many C implementations
	it is possible to corrupt the execution stack by writing past
	the end of an array declared auto in a routine.  Code that does
	this is said to smash the stack, and can cause return from the
	routine to jump to a random address.  This can produce some of
	the most insidious data-dependent bugs known to mankind.
	Variants include trash the stack, scribble the stack, mangle
	the stack; the term mung the stack is not used, as this is
	never done intentionally. See spam; see also alias bug,
	fandango on core, memory leak, precedence lossage, overrun screw.

INTRODUCTION
   Over the last few months there has been a large increase of buffer
overflow vulnerabilities being both discovered and exploited.  Examples
of these are syslog, splitvt, sendmail 8.7.5, Linux/FreeBSD mount, Xt 
library, at, etc.  This paper attempts to explain what buffer overflows 
are, and how their exploits work.

   Basic knowledge of assembly is required.  An understanding of virtual 
memory concepts, and experience with gdb are very helpful but not necessary.
We also assume we are working with an Intel x86 CPU, and that the operating 
system is Linux.

   Some basic definitions before we begin: A buffer is simply a contiguous 
block of computer memory that holds multiple instances of the same data 
type.  C programmers normally associate with the word buffer arrays. Most 
commonly, character arrays.  Arrays, like all variables in C, can be 
declared either static or dynamic.  Static variables are allocated at load 
time on the data segment.  Dynamic variables are allocated at run time on 
the stack. To overflow is to flow, or fill over the top, brims, or bounds. 
We will concern ourselves only with the overflow of dynamic buffers, otherwise
known as stack-based buffer overflows.


                          Process Memory Organization
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~

   To understand what stack buffers are we must first understand how a
process is organized in memory.  Processes are divided into three regions:
Text, Data, and Stack.  We will concentrate on the stack region, but first
a small overview of the other regions is in order.

   The text region is fixed by the program and includes code (instructions)
and read-only data.  This region corresponds to the text section of the
executable file.  This region is normally marked read-only and any attempt to
write to it will result in a segmentation violation.

   The data region contains initialized and uninitialized data.  Static
variables are stored in this region.  The data region corresponds to the
data-bss sections of the executable file.  Its size can be changed with the
brk(2) system call.  If the expansion of the bss data or the user stack
exhausts available memory, the process is blocked and is rescheduled to
run again with a larger memory space. New memory is added between the data
and stack segments.

                             /------------------\  lower
                             |                  |  memory
                             |       Text       |  addresses
                             |                  |
                             |------------------|
                             |   (Initialized)  |
                             |        Data      |
                             |  (Uninitialized) |
                             |------------------|
                             |                  |
                             |       Stack      |  higher
                             |                  |  memory
                             \------------------/  addresses

                         Fig. 1 Process Memory Regions


                               What Is A Stack?
                               ~~~~~~~~~~~~~~~~

   A stack is an abstract data type frequently used in computer science.  A
stack of objects has the property that the last object placed on the stack
will be the first object removed.  This property is commonly referred to as
last in, first out queue, or a LIFO.

   Several operations are defined on stacks.  Two of the most important are
PUSH and POP.  PUSH adds an element at the top of the stack.  POP, in 
contrast, reduces the stack size by one by removing the last element at the 
top of the stack.


                            Why Do We Use A Stack?
                            ~~~~~~~~~~~~~~~~~~~~~~

   Modern computers are designed with the need of high-level languages in
mind.  The most important technique for structuring programs introduced by
high-level languages is the procedure or function.  From one point of view, a
procedure call alters the flow of control just as a jump does, but unlike a
jump, when finished performing its task, a function returns control to the 
statement or instruction following the call.  This high-level abstraction
is implemented with the help of the stack.

  The stack is also used to dynamically allocate the local variables used in
functions, to pass parameters to the functions, and to return values from the
function.


                               The Stack Region
                               ~~~~~~~~~~~~~~~~

   A stack is a contiguous block of memory containing data.  A register called
the stack pointer (SP) points to the top of the stack.  The bottom of the 
stack is at a fixed address.  Its size is dynamically adjusted by the kernel 
at run time. The CPU implements instructions to PUSH onto and POP off of the 
stack. 

   The stack consists of logical stack frames that are pushed when calling a
function and popped when returning.  A stack frame contains the parameters to 
a function, its local variables, and the data necessary to recover the 
previous stack frame, including the value of the instruction pointer at the 
time of the function call.

   Depending on the implementation the stack will either grow down (towards
lower memory addresses), or up.  In our examples we'll use a stack that grows
down.  This is the way the stack grows on many computers including the Intel, 
Motorola, SPARC and MIPS processors.  The stack pointer (SP) is also
implementation dependent.  It may point to the last address on the stack, or 
to the next free available address after the stack.  For our discussion we'll
assume it points to the last address on the stack.

   In addition to the stack pointer, which points to the top of the stack
(lowest numerical address), it is often convenient to have a frame pointer
(FP) which points to a fixed location within a frame.  Some texts also refer
to it as a local base pointer (LB).  In principle, local variables could be
referenced by giving their offsets from SP.  However, as words are pushed onto
the stack and popped from the stack, these offsets change.  Although in some
cases the compiler can keep track of the number of words on the stack and
thus correct the offsets, in some cases it cannot, and in all cases
considerable administration is required.  Futhermore, on some machines, such
as Intel-based processors, accessing a variable at a known distance from SP
requires multiple instructions.

   Consequently, many compilers use a second register, FP, for referencing
both local variables and parameters because their distances from FP do
not change with PUSHes and POPs.  On Intel CPUs, BP (EBP) is used for this 
purpose.  On the Motorola CPUs, any address register except A7 (the stack 
pointer) will do.  Because the way our stack grows, actual parameters have 
positive offsets and local variables have negative offsets from FP.

   The first thing a procedure must do when called is save the previous FP
(so it can be restored at procedure exit).  Then it copies SP into FP to 
create the new FP, and advances SP to reserve space for the local variables. 
This code is called the procedure prolog.  Upon procedure exit, the stack 
must be cleaned up again, something called the procedure epilog.  The Intel 
ENTER and LEAVE instructions and the Motorola LINK and UNLINK instructions, 
have been provided to do most of the procedure prolog and epilog work 
efficiently. 

   Let us see what the stack looks like in a simple example:

example1.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
}

void main() {
  function(1,2,3);
}
------------------------------------------------------------------------------

   To understand what the program does to call function() we compile it with
gcc using the -S switch to generate assembly code output:

$ gcc -S -o example1.s example1.c

   By looking at the assembly language output we see that the call to
function() is translated to:

        pushl $3
        pushl $2
        pushl $1
        call function

    This pushes the 3 arguments to function backwards into the stack, and
calls function().  The instruction 'call' will push the instruction pointer
(IP) onto the stack.  We'll call the saved IP the return address (RET).  The
first thing done in function is the procedure prolog:

        pushl %ebp
        movl %esp,%ebp
        subl $20,%esp

   This pushes EBP, the frame pointer, onto the stack.  It then copies the
current SP onto EBP, making it the new FP pointer.  We'll call the saved FP
pointer SFP.  It then allocates space for the local variables by subtracting
their size from SP.

   We must remember that memory can only be addressed in multiples of the
word size.  A word in our case is 4 bytes, or 32 bits.  So our 5 byte buffer
is really going to take 8 bytes (2 words) of memory, and our 10 byte buffer
is going to take 12 bytes (3 words) of memory.  That is why SP is being
subtracted by 20.  With that in mind our stack looks like this when
function() is called (each space represents a byte):


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]
	   
top of                                                            bottom of
stack                                                                 stack


                               Buffer Overflows
                               ~~~~~~~~~~~~~~~~

   A buffer overflow is the result of stuffing more data into a buffer than
it can handle.  How can this often found programming error can be taken
advantage to execute arbitrary code?  Lets look at another example:

example2.c
------------------------------------------------------------------------------
void function(char *str) {
   char buffer[16];

   strcpy(buffer,str);
}

void main() {
  char large_string[256];
  int i;

  for( i = 0; i < 255; i++)
    large_string[i] = 'A';

  function(large_string);
}
------------------------------------------------------------------------------

   This is program has a function with a typical buffer overflow coding
error.  The function copies a supplied string without bounds checking by
using strcpy() instead of strncpy().  If you run this program you will get a
segmentation violation.  Lets see what its stack looks when we call function:


bottom of                                                            top of
memory                                                               memory
                  buffer            sfp   ret   *str
<------          [                ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   What is going on here?  Why do we get a segmentation violation?  Simple.
strcpy() is coping the contents of *str (larger_string[]) into buffer[]
until a null character is found on the string.  As we can see buffer[] is
much smaller than *str.  buffer[] is 16 bytes long, and we are trying to stuff
it with 256 bytes.  This means that all 250 bytes after buffer in the stack
are being overwritten.  This includes the SFP, RET, and even *str!  We had 
filled large_string with the character 'A'.  It's hex character value
is 0x41.  That means that the return address is now 0x41414141.  This is
outside of the process address space.  That is why when the function returns
and tries to read the next instruction from that address you get a 
segmentation violation.

   So a buffer overflow allows us to change the return address of a function.
In this way we can change the flow of execution of the program.  Lets go back
to our first example and recall what the stack looked like:


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   Lets try to modify our first example so that it overwrites the return
address, and demonstrate how we can make it execute arbitrary code.  Just
before buffer1[] on the stack is SFP, and before it, the return address.
That is 4 bytes pass the end of buffer1[].  But remember that buffer1[] is
really 2 word so its 8 bytes long.  So the return address is 12 bytes from
the start of buffer1[].  We'll modify the return value in such a way that the
assignment statement 'x = 1;' after the function call will be jumped.  To do
so we add 8 bytes to the return address.  Our code is now:

example3.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
   int *ret;

   ret = buffer1 + 12;
   (*ret) += 8;
}

void main() {
  int x;

  x = 0;
  function(1,2,3);
  x = 1;
  printf("%d\n",x);
}
------------------------------------------------------------------------------

   What we have done is add 12 to buffer1[]'s address.  This new address is
where the return address is stored.  We want to skip pass the assignment to
the printf call.  How did we know to add 8 to the return address?  We used a
test value first (for example 1), compiled the program, and then started gdb:

------------------------------------------------------------------------------
[aleph1]$ gdb example3
GDB is free software and you are welcome to distribute copies of it
 under certain conditions; type "show copying" to see the conditions.
There is absolutely no warranty for GDB; type "show warranty" for details.
GDB 4.15 (i586-unknown-linux), Copyright 1995 Free Software Foundation, Inc...
(no debugging symbols found)...
(gdb) disassemble main
Dump of assembler code for function main:
0x8000490 <main>:       pushl  %ebp
0x8000491 <main+1>:     movl   %esp,%ebp
0x8000493 <main+3>:     subl   $0x4,%esp
0x8000496 <main+6>:     movl   $0x0,0xfffffffc(%ebp)
0x800049d <main+13>:    pushl  $0x3
0x800049f <main+15>:    pushl  $0x2
0x80004a1 <main+17>:    pushl  $0x1
0x80004a3 <main+19>:    call   0x8000470 <function>
0x80004a8 <main+24>:    addl   $0xc,%esp
0x80004ab <main+27>:    movl   $0x1,0xfffffffc(%ebp)
0x80004b2 <main+34>:    movl   0xfffffffc(%ebp),%eax
0x80004b5 <main+37>:    pushl  %eax
0x80004b6 <main+38>:    pushl  $0x80004f8
0x80004bb <main+43>:    call   0x8000378 <printf>
0x80004c0 <main+48>:    addl   $0x8,%esp
0x80004c3 <main+51>:    movl   %ebp,%esp
0x80004c5 <main+53>:    popl   %ebp
0x80004c6 <main+54>:    ret
0x80004c7 <main+55>:    nop
------------------------------------------------------------------------------

   We can see that when calling function() the RET will be 0x8004a8, and we
want to jump past the assignment at 0x80004ab.  The next instruction we want
to execute is the at 0x8004b2.  A little math tells us the distance is 8
bytes.


                                  Shell Code
                                  ~~~~~~~~~~

   So now that we know that we can modify the return address and the flow of
execution, what program do we want to execute?  In most cases we'll simply
want the program to spawn a shell.  From the shell we can then issue other
commands as we wish.  But what if there is no such code in the program we
are trying to exploit?  How can we place arbitrary instruction into its
address space?  The answer is to place the code with are trying to execute in
the buffer we are overflowing, and overwrite the return address so it points
back into the buffer.  Assuming the stack starts at address 0xFF, and that S
stands for the code we want to execute the stack would then look like this:


bottom of  DDDDDDDDEEEEEEEEEEEE  EEEE  FFFF  FFFF  FFFF  FFFF     top of
memory     89ABCDEF0123456789AB  CDEF  0123  4567  89AB  CDEF     memory
           buffer                sfp   ret   a     b     c

<------   [SSSSSSSSSSSSSSSSSSSS][SSSS][0xD8][0x01][0x02][0x03]
           ^                            |
           |____________________________|
top of                                                            bottom of
stack                                                                 stack


The code to spawn a shell in C looks like:

shellcode.c
-----------------------------------------------------------------------------
#include <stdio.h>

void main() {
   char *name[2];

   name[0] = "/bin/sh";
   name[1] = NULL;
   execve(name[0], name, NULL);
}
------------------------------------------------------------------------------

   To find out what does it looks like in assembly we compile it, and start
up gdb.  Remember to use the -static flag. Otherwise the actual code the
for the execve system call will not be included.  Instead there will be a
reference to dynamic C library that would normally would be linked in at
load time.

------------------------------------------------------------------------------
[aleph1]$ gcc -o shellcode -ggdb -static shellcode.c





ANDROID SECURITY
App review before distribution -iOS: Apple manual and automated vetting; Android -  Easier to get app placed on market,Transparent automated scanning, removal via Bouncer
App isolation and protection - Sandboxing and restricted permission ;Android - Permission model ( runtime, dangerous/ normal) ,Defense against circumvention.
ANDROID CORE SECURITY FEATURES:
•	The Android Application Sandbox, isolates app data and code execution from other apps.
•	App framework with Implementations of common security functionality such as cryptography, permissions, and secure IPC.
•	Technologies like ASLR, NX, ProPolice, safe_iop, OpenBSD dlmalloc, OpenBSD calloc, and Linux mmap_min_addr to mitigate risks associated with common memory management errors.
•	An encrypted file system that can be enabled
•	User-granted permissions to restrict access to system features and user data.
•	Application-defined permissions to control application data on a per-app basis.
THREATS TO MOBILE APPLICATIONS:
•	Privacy: Data leakage, identifier leakage, third-party tags and libraries, location privacy
•	Security: Phishing, malware & drive-bys, malicious intents on Android, Ikee/Zitmo and other mobile malware.
OWASP Mobile Top Ten:
M1This category covers misuse of a platform feature or failure to use platform security controls. It might include Android intents, platform permissions, misuse of TouchID, the Keychain, or some other security control that is part of the mobile operating system. There are several ways that mobile apps can experience this risk.
M2: This new category is a combination of M2 + M4 from Mobile Top Ten 2014. This covers insecure data storage and unintended data leakage.
M3: This covers poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
M4: This category captures notions of authenticating the end user or bad session management. This can include:
Failing to identify the user at all when that should be required
Failure to maintain the user's identity when it is required
Weaknesses in session management
M5: Insufficient Cryptography : wrong crypto usage 
M6: Insecure Authorization
M7: Client Code Quality Issues : client side eg buffer overflows 
M8: Code Tampering : attacker nodification (code, memory etc) 
M9: Reverse Engineering : by attacker and gaining info 
M10: Extraneous Functionality : hidden back door or password in comment by mistake etc .
•	M1: misuse of a platform feature or failure to use platform security controls. egAndroid intents, platform permissions, misuse of TouchID, the Keychain, or some other security control 
•	M2: covers insecure data storage and unintended data leakage.
•	M3: poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
•	M4: authenticating end user or bad session management. This can include:Failing to identify the user at all when that should be required, Failure to maintain the user's identity when it is required. Weaknesses in session management.
MOBILE MALWARE EXAMPLES:
•	DroidDream (Android)
o	Over 58 apps uploaded to Google app market
o	Conducts data theft; send credentials to attacker
o	Trozan, gained root access
•	Ikee (iOS)
o	Worm capabilities (targeted default ssh pwd)
o	Worked only on jailbroken phones with ssh installed 
o	Zitmo (Symbian,BlackBerry,Windows,Android)
o	Propagates via SMS; claims to install a “security certificate”
o	Captures info from SMS; aimed at defeating 2-factor auth 
o	Works with Zeus botnet; timed with user PC infection.
COMPARISON BETWEEN PLATFORMS: 
•	Approval process for applications
o	Market: Vendor controlled/Open
o	App signing: Vendor-issued/self-signed
o	User approval of permission
•	Programming language for applications
o	Managed execution: Java, .Net 
o	Native execution: Objective C0.
ANDROID:
•	Platform outline:
o	Linux kernel, browser, SQL-lite database
o	Software for secure network communication
	Open SSL, Bouncy Castle crypto API and Java library 
o	C language infrastructure
o	Java platform for running applications
	Dalvik bytecode, virtual machine
                              ,         

ANDROID MARKET:
•	Self-signed apps
•	App permissions granted on user installation
•	Open market -  Bad applications may show up on market;Shifts focus from remote exploit to privilege escalation.
ANDROID PERMISSIONS:
•	Example of permissions provided by Android
o	“android.permission.INTERNET”
o	“android.permission.READ_EXTERNAL_STORAGE 
o	“android.permission.SEND_SMS”
o	“android.permission.BLUETOOTH” 
•	Also possible to define custom permissions
ANDROID PERMISSION MODEL:
Google maps or Uber asking for location permission to be switched on.
 
 
SECURITY FEATURES:
•	Isolation
o	Multi-user Linux operating system 
o	Each application normally runs as a different user
•	Communication between applications
o	May share same Linux user ID
	Access files from each other
	May share same Linux process and Dalvik VM
o	Communicate through application framework
	“Intents,” based on Binder, discussed in a few slides
•	Battery life
o	Developers must conserve power
o	Applications store state so they can be stopped (to save power) and restarted.
APPLICATION  SANDBOX:
o	Each application runs with its UID in its own Dalvik virtual machine
	Provides CPU protection, memory protection
	Authenticated communication protection using Unix domain sockets
	Only ping, zygote (spawn another process) run as root
o	Applications announce permission requirement
	Create a whitelist model – user grants access
	Don’t interrupt user  – all questions asked as install time
	Inter-component communication reference monitor checks permissions.
EXPLOIT PREVENTION:
	Open source: public review, no obscurity
	Goals
o	Prevent remote attacks, privilege escalation
o	Secure drivers, media codecs, new and custom features
	Overflow prevention
o	ProPolice stack protection
	First on the ARM architecture
o	Some heap overflow protections
	Chunk consolidation in DL malloc (from OpenBSD)
	ASLR (Address Space Layout Randomisation) 
o	Avoided in initial release
	Many pre-linked images for performance 
o	Later developed and contributed by Bojinov, Boneh.
DLMALLOC: 
	Stores meta data in band 
	Heap consolidation attack
o	Heap overflow can overwrite pointers to previous and next unconsolidated chunks
o	Overwriting these pointers allows remote code execution
	Change to improve security
o	Check integrity of forward and backward pointers
	Simply check that back-forward-back = back,  f-b-f=f
o	Increases the difficulty of heap overflow
APPLICATION DEVELOPMENT CONCEPTS:
	Activity – one-user task
o	Example: scroll through your inbox
o	Email client comprises many activities
	Service – Java daemon that runs in background
o	Example: application that streams an mp3 in background
	Intents – asynchronous messaging system
o	Fire an intent to switch from one activity to another
o	Example: email app has inbox, compose activity, viewer activity
	User click on inbox entry fires an intent to the viewer activity, which then allows user to view that email
	Content provider
o	Store and share data using a relational database interface 
	Broadcast receiver
o	 “mailboxes” for messages from other applications
ANDROID INTENTS: 
	Message between components in same or different app
	Intent is a bundle of information, e.g.,  
o	action to be taken
o	data to act on
o	category of component to handle the intent
o	instructions on how to launch a target activity
	Routing can be
o	Explicit: delivered only to a specific receiver 
o	Implicit: all components that have registered to receive that action will get the message
 
 
SECURITY ISSUES WITH INTENTS:
	Sender of an intent can verify that the recipient has a permission by specifying a permission with the method call
	Senders can use explicit intents to send the message to a single component (avoiding broadcasting)
	Receivers have to handle malicious intents
ATTACK : PERMISSION REDELEGATION
	Definition: an application without a permission gains additional privileges through another application 
	Example of the “confused deputy” problem 
   
	App w/ permissions exposes a public interface
	Study in 2011
o	Examine 872 apps
o	320 of these (37%) have permissions and at least one type of public component
o	Construct attacks using 15 vulnerabilities in 5 apps
POWER CONTROL WIDGET:
	Can change Wi-fi, BT, GPS, Data Sync, Screen Brightness with only one click 
	Uses Intent to communicate the event of switching settings
A malicious app without permissions can send a fake Intent to the Power Control Widget, simulating click to switch settings
Principle of least privilege works but is not a solution. Apps with permissions need to manage security.
JAVA SANDBOX:
	Four complementary mechanisms
o	Class loader
	Separate namespaces for separate class loaders
	Associates protection domain with each class 
o	Verifier and JVM run-time tests
	NO unchecked casts or other type errors, NO array overflow
	Preserves private, protected visibility levels
o	Security Manager
	Called by library functions to decide if request is allowed
	Uses protection domain associated with code, user policy
STACK INSPECTION: 
•	Permission depends on
o	Permission of calling method
o	Permission of all methods above it on stack
	Up to method that is trusted and asserts this trust 
MAC OS APPLICATION DEVELOPMENT:
•	Apps developed in Objective-C using Apple SDK
•	model based on touch events
•	FoundEvent-handling ation and UIKit frameworks provide the key services used by all iOS applications



MAC OS PLATFORM:
 

 

APP SECURITY:
•	Runtime protection
o	System resources, kernel shielded from user apps
o	App “sandbox” prevents access to other app’s data 
o	Inter-app communication only through iOS APIs 
o	Code generation prevented
•	Mandatory code signing
o	All apps must be signed using Apple-issued certificate
•	Application data protection
o	Apps can leverage built-in hardware encryption
IOS SANDBOX:
•	Limit app’s access to files, preferences, network, other resources
•	Each app has own sandbox directory
•	Limits consequences of attacks
•	Same privileges for each app
FILE ENCRYPTION:
•	The content of a file is encrypted with a per-file key, which is wrapped with a class key and stored in a file’s metadata, which is in turn encrypted with the file system key. 
o	When a file is opened, its metadata is decrypted with the file system key, revealing the wrapped per-file key and a notation on which class protects it 
o	The per-file key is unwrapped with the class key, then supplied to the hardware AES engine, decrypting the file as it is read from flash memory
•	The metadata of all files is encrypted with a random key. Since it’s stored on the device, used only for quick erased on demand.
 
MASQUE ATTACK:
•	iOS app installed using enterprise/ad-hoc provisioning could replace genuine app installed through the App Store, if both apps have same bundle identifier
•	This vulnerability existed because iOS didn't enforce matching certificates for apps with the same bundle identifier 
COMPARISON OF MAC OS VS ANDROID:
•	App approval process
o	Android apps from open app store
o	iOS vendor-controlled store of vetted apps
•	Application permissions
o	Android permission based on install-time manifest
o	All iOS apps have same set of “sandbox” privileges
•	App programming language
o	Android apps written in Java; no buffer overflow…
o	iOS apps written in Objective-C
	iOS	Android	Windows
Unix	x	x	
Windows			
Open market		x	
Closed market	x		
Vendor signed	x		
Self-signed		x	
User approval of permissions		x	
Managed code		x	
Native code	x		

MOST SIGNIFICANT VULNERABILITIES:
	Loading untrusted web content
	Leaking URLs to foreign apps
	Exposing state changing navigation to foreign apps


BUFFER OVERFLOW
EXPLANATION FOR LAST PROGRAM:
Figure 11.12a illustrates such a vulnerable program (which shares many similarities with Figure 11.11a, except that the structure is declared as a global variable). The design of the attack is very similar, indeed only the target address changes. The global structure was found to be at address 0x08049740, which was used as the target address in the attack. Note that global variables do not usually change location, as their addresses are used directly in the program code. The attack script and result of successfully executing it are shown in the text in Figure 11.12b.
MALICIOUS SOFTWARE:
	programs exploiting system vulnerabilities
	known as malicious software or malware 
o	program fragments that need a host program
	e.g. viruses, logic bombs, and backdoors 
o	independent self-contained programs
	e.g. worms, bots
o	replicating or not
	sophisticated threat to computer systems

MALWARE TECHNOLOGY:
	Mobile code software : can be shipped unchanged to a heterogeneous collection of platforms and execute with identical semantics
	Auto-rooter malicious hacker tools : used to break into new machines remotely Kit (virus generator) Set of tools for generating new viruses automatically 
	Spammer and Flooder programs : used to send large volumes of unwanted e-mail, or to attack systems with a large volumes of traffic to carry out a DoS attack.
VIRUS:
	piece of software that infects programs
o	modifying them to include a copy of the virus
o	so it executes secretly when host program is run
	specific to operating system and hardware
o	taking advantage of their details and weaknesses
	a typical virus goes through phases of:
o	dormant
o	propagation
o	triggering
o	execution
Email Viruses
A more recent development in malicious software is the e-mail virus. The first rapidly spreading e-mail viruses, such as Melissa, made use of a Microsoft Word macro embedded in an attachment. If the recipient opens the e-mail attachment, the Word macro is activated. Then the e-mail virus sends itself to everyone on the mailing list in the user's e-mail package, and also does local damage.
At the end of 1999, a more powerful version of the e-mail virus appeared. This newer version can be activated merely by opening an e-mail that contains the virus rather than opening an attachment. The virus uses the Visual Basic scripting language supported by the e-mail package.
Thus we see a new generation of malware that arrives via e-mail and uses e-mail software features to replicate itself across the Internet. The virus propagates itself as soon as activated (either by opening an e-mail attachment of by opening the e-mail) to all of the e-mail addresses known to the infected host. As a result, whereas viruses used to take months or years to propagate, they now do so in hours. This makes it very difficult for antivirus software to respond before much damage is done. Ultimately, a greater degree of security must be built into Internet utility and application software on PCs to counter the growing threat.
DIGITAL IMMUNE SYSTEM:
Comprehensive approach to virus protection developed by IBM and subsequently refined by Symantec
When a new virus enters an organization, the immune system automatically captures it, analyzes it, adds detection and shielding for it, removes it, and passes information about that virus to other systems so that it can be detected before it is allowed to run elsewhere
	1. A monitoring program on each PC uses a variety of heuristics to infer that a virus may be present, and forwards a copy to an administrative machine.
	2. The admin machine encrypts this and sends it to a central virus analysis machine.
	3. This machine creates an environment in which the infected program can be safely run for analysis. The virus analysis machine then produces a prescription for identifying and removing the virus.
	 4. The resulting prescription is sent back to the administrative machine. 
	5.  The administrative machine forwards the prescription to the infected client.
	 6. The prescription is also forwarded to other clients in the organization.
	 7. Subscribers worldwide receive regular antivirus updates to protect from new virus
The success of the digital immune system depends on the ability of the virus analysis machine to detect new and innovative virus strains.

  
 
BEHAVIOURAL BLOCKING SOFTWARE:
Unlike heuristics or fingerprint-based scanners, behavior-blocking software integrates with the operating system of a host computer and monitors program behavior in real-time for malicious actions. The behavior blocking software then blocks potentially malicious actions before they can affect the system. Monitored behaviors can include
• Attempts to open, view, delete, and/or modify files;
• Attempts to format disk drives and other unrecoverable disk operations;
• Modifications to the logic of executable files or macros;
• Modification of critical system settings, such as start-up settings;
• Scripting of e-mail and instant messaging clients to send executable content; and
• Initiation of network communications.
Figure 7.5 illustrates its operation. Behavior-blocking software runs on server and desktop computers and is instructed through policies set by the network administrator to let benign actions take place but to intercede when unauthorized or suspicious actions occur. The module blocks any suspicious software from executing. A blocker isolates the code in a sandbox, which restricts the code's access to various OS resources and applications. The blocker then sends an alert. Because behavior blocker can block suspicious software in real-time, it has an advantage over such established antivirus detection techniques as fingerprinting or heuristics. Behavior blocking alone has limitations. Because the malicious code must run on the target machine before all its behaviors can be identified, it can cause harm before it has been detected and blocked. 
MORRIS WORM: Until the current generation of worms, the best known was the worm released onto the Internet by Robert Morris in 1988. The Morris worm was designed to spread on UNIX systems and used a number of different techniques for propagation. When a copy began execution, its first task was to discover other hosts known to this host that would allow entry from this host. The worm performed this task by examining a variety of lists and tables, including system tables that declared which other machines were trusted by this host, users' mail forwarding files, tables by which users gave themselves permission for access to remote accounts, and from a program that reported the status of network connections. For each discovered host, the worm tried a number of methods for gaining access:
1.	 It attempted to log on to a remote host as a legitimate user, having cracked the local password file, and assuming that many users use the same password on different systems. 
2.	 It exploited a bug in the finger protocol
3.	It exploited a trapdoor in the debug option of the remote sendmail process.
If any of these attacks succeeded, the worm achieved communication with the operating system command interpreter. It then sent this interpreter a short bootstrap program, issued a command to execute that program, and then logged off. The bootstrap program then called back the parent program and downloaded the remainder of the worm. The new worm was then executed.
WORM COUNTERMEASURES:
There is considerable overlap in techniques for dealing with viruses and worms. Once a worm is resident on a machine, antivirus software can be used to detect it. In addition, because worms propagation generates considerable network activity, the monitoring of that activity can lead form the basis of a worm defense. Have classes: 
A.	Signature-based worm scan filtering: generates a worm signature, which is then used to prevent worm scans from entering/leaving a network/host. 
B.	Filter-based worm containment: focuses on worm content rather than a scan signature. The filter checks a message to determine if it contains worm code.
C.	Payload-classification-based worm containment: examine packets to see if they contain a worm using anomaly detection techniques 
D.	Threshold random walk (TRW) scan detection: exploits randomness in picking destinations to connect to as a way of detecting if a scanner is in operation 
E.	Rate limiting: limits the rate of scanlike traffic from an infected host. 
F.	Rate halting: immediately blocks outgoing traffic when a threshold is exceeded either in outgoing connection rate or diversity of connection attempts. Rate halting can integrate with a signature- or filter-based approach so that once a signature or filter is generated, every blocked host can be unblocked; as with rate limiting, rate halting techniques are not suitable for slow, stealthy worms. 

PROACTIVE WORM CONTAINMENT:
The Proactive Worm Containment (PWC) scheme is host based software that looks for surges in the rate of frequency of outgoing connection attempts and the diversity of connections to remote hosts. When such a surge is detected, the software immediately blocks its host from further connection attempts. A deployed PWC system consists of a PWC manager and PWC agents in hosts. Figure 7.7 from the text is an example of an architecture that includes PWC, which operates as detailed: 
A.	 A PWC agent monitors outgoing traffic for scan activity, determined by a surge in UDP / TCP connection attempts to remote hosts. If a surge is detected, the agent: 1) issues an alert to local system; 2) blocks all outgoing connection attempts; 3) transmits the alert to the PWC manager; and  4) starts a relaxation analysis. 
B. A PWC manager receives an alert, and propagates the alert to all other agents.
C. The host receives an alert, and must decide whether to ignore the alert. If the time since the last incoming packet has been sufficiently long so that the agent would have detected a worm if infected, then the alert is ignored. Otherwise, the agent assumes that it might be infected and performs the following actions:(1) blocks all outgoing connection attempts from the specific alerting port;and (2) starts a relaxation analysis. 
D. Relaxation analysis. An agent monitors outgoing activity for a fixed window of time to see if outgoing connections exceed a threshold. If so, blockage is continued and relaxation analysis is repeated until the outgoing connection rate drops below the threshold, at which time the agent removes the block. If the threshold continues to be exceeded over a sufficient number of relaxation windows, the agent isolates the host and reports to the PWC manager. 
Meanwhile, a signature extractor functions as a passive sensor that monitors all traffic and attempts to detect worms by signature analysis. 

NETWORK BASED WORM DEFENSE
The key element of a network-based worm defense is worm monitoring software. Two types of monitoring software are needed: 
• Ingress monitors: located at the border between the enterprise network and the Internet, in a border router, external firewall, separate passive monitor, or honeypot.
• Egress monitors: located at the egress point of individual LANs on the enterprise network as well as at the external border, in a LAN router or switch, external firewall or honeypot. The two types of monitors can be collocated. It is designed to catch the source of a worm attack by monitoring outgoing traffic for signs of scanning etc.
Worm monitors can act in the manner of intrusion detection systems and generate alerts to a central administrative system. It is also possible to implement a system that attempts to react in real time to a worm attack, so as to counter zero-day exploits effectively. This is similar to the approach taken with the digital immune system (Figure 7.4). Figure 7.8 shows an example of a worm countermeasure architecture that works as :
1.	Sensors deployed at various network locations detect a potential worm.
2. and send alerts to a central server that correlates / analyzes incoming alerts.
3. forwards info to a protected environment, where worm is sandboxed for analysis 
4. protected system tests the suspicious software against an appropriately instrumented version of the targeted application to identify the vulnerability. 
5. protected system generates one or more software patches and tests these.
6. system sends the patch to the application host to update the targeted application. 

INTERNET SECURITY PROTOCOLS AND STANDARDS
IPSec ensures TCP and application protocol is encrypted – and much of IP too.
With SSL or TLS, IP and TCP are not encrypted.
Benefits in routing applications:
	A routing advertisement : comes from an authorised router
	A neighbour advertisement
	A redirect message comes from router to which initial message was sent
	A routing update is not forged
	An ICMP redirect is an error message sent by a router to the sender of an IP packet . Redirects are used when a router believes a packet is being routed sub optimally and it would like to inform the sending host that it should forward subsequent packets to that same destination through a different gateway.
 

 
AUTHENTICATION HEADER: The Authentication Header provides support for data integrity and authentication of IP packets.The data integrity feature ensures that undetected modification to a packet’s content in transit is not possible. The authentication feature enables an end system or network device to authenticate the user or application and filter traffic accordingly; it also prevents address spoofing attacks and replay attacks. Authentication is based on the use of a message authentication code (MAC), hence the two parties must share a secret key. AH supports MACs using HMAC-MD5-96 or HMAC-SHA-1-96. Both of these use the HMAC algorithm , the first with the MD5 hash code and the second with the SHA-1 hash code. In both cases, the full HMAC value is calculated but then truncated by using the first 96-bits, which is the default length for the Authentication Data field.
ENCAPSULATION SECURITY PAYLOAD  (ESP):
	Provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality 
	As an optional feature, ESP can also provide an authentication service, with the same MACs as AH
	Padding used based on need on encryption algorithm used, also used for limited data confidentiality by concealing actual length of flow
 
Figure 21.4 shows the Authentication Header fields:
• Next Header (8 bits): Identifies the type of header immediately following this header
• Payload Length (8 bits): Length of Authentication Header in 32-bit words, minus 2. 
• Reserved (16 bits): For future use
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value
• Authentication Data (variable): A variable-length field (must be an integral number of 32-bit words) that contains the Integrity Check Value (ICV), or MAC,for this packet
The authentication data field is calculated over
• IP header fields that either do not change in transit (immutable) or that are predictable in value upon arrival at the endpoint for the AH SA. 
• The AH header other than the Authentication Data field. The Authentication Data field is set to zero for purposes of calculation at both source and destination. 
• The entire upper-level protocol data, which is assumed to be immutable in transit.

ENCAPSULATION SECURITY PAYLOAD:

The Encapsulating Security Payload provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality. As an optional feature, ESP can also provide an authentication service, with the same MACs as AH. ESP supports range of ciphers, modes, and padding, as shown.
 Figure 21.5 shows the format of an ESP packet. It contains the following fields:
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value; this provides an anti-replay function ,as discussed for AH
• Payload Data (variable): This is a transport-level segment (transport mode) or IP packet (tunnel mode) that is protected by encryption
• Padding (0–255 bytes): for various reasons
• Pad Length (8 bits): Indicates the number of pad bytes immediately preceding this field
• Next Header (8 bits): Identifies the type of data contained in the payload data field by identifying the first header in that payload 
• Authentication Data (variable): A variable-length field that contains the Integrity Check Value computed over the ESP packet minus the Authentication Data field 
TRANSPORT VS TUNNEL MODE:
Stallings Figure 16.5 shows the difference between end-to-end (transport) mode and end-to-intermediate (tunnel) mode.
Transport mode provides protection primarily for upper-layer protocol payloads, by inserting the AH after the original IP header and before the IP payload. Typically, transport mode is used for end-to-end communication between two hosts.
Tunnel mode provides protection to the entire IP, after the AH or ESP fields are added to the IP packet, the entire packet plus security fields is treated as the payload of new “outer”IP packet with a new outer IP header. Tunnel mode is used when one or both ends of an SA are a security gateway, such as a firewall or router that implements IPSec. 


 
 

 
KEY MANAGEMENT:
The key management portion of IPSec involves the determination and distribution of secret keys. A typical requirement is four keys for communication between two applications: transmit and receive pairs for both AH and ESP. The IPSec Architecture document mandates support for two types of key management:
• Manual where a system administrator manually configures each system with its own keys and with the keys of other communicating 
• Automated where an automated system enables the on-demand creation of keys for SAs and facilitates the use of keys in a large distributed system with an evolving configuration
The default automated key management protocol for IPSec is referred to as ISAKMP/Oakley.
Default Key Management protocol for IPSEC is ISAKMP/Oakley. Following elements
	Oakley Key Determination protocol : Based on Diffie-Hellman algorithm but providing added security to avoid man in middle attack
	Internet Security Association and Key Management Protocol (ISAKMP) Framework for Internet Key management and provides specific protocol support 


PUBLIC KEY ENCRYPTION:
Main Characteristics or differentiating factors
	Digest Length
	Basic Unit of processing ( input block length )
	Number of steps
	Maximum message size
	Number of primitive logical functions
	Number of additive constants used
HMAC: In recent years, there has been increased interest in developing a MAC derived from a cryptographic hash code, such as SHA-1, since these are usually faster, and code is widely available. A hash function such as SHA-1 was not designed for use as a MAC and cannot be used directly for that purpose because it does not rely on a secret key. There have been a number of proposals for the incorporation of a secret key into an existing hash algorithm. The approach that has received the most support is HMAC. 
HMAC has been issued as RFC 2104, has been chosen as the mandatory-to-implement MAC for IP Security, and is used in other Internet protocols, such as Transport Layer Security (TLS, soon to replace Secure Sockets Layer) and Secure Electronic Transaction (SET). HMAC treats the hash function as a "black box." This has two benefits. First, an existing implementation of a hash function can be used as a module in implementing HMAC. In this way, the bulk of the HMAC code is prepackaged and ready to use without modification. Second, if it is ever desired to replace a given hash function in an HMAC implementation, all that is required is to remove the existing hash function module and drop in the new module. This could be done if a faster hash function were desired. More important, if the security of the embedded hash function were compromised, the security of HMAC could be retained simply by replacing the embedded hash function with a more secure one. Also, HMAC can be proven secure provided that the embedded hash function has some reasonable cryptographic strengths. 
CRYPTOGRAPHIC HASH FUNCTION – HMAC :
Design Objectives
	Developing MAC from Cryptographic hash code ( relies on secret key)
	To be able to use existing hash functions without modification
	Allow easy replaceability of embedded hash function in case faster or more secure functions are found
	No degradation on performance from original hash function
	Handle keys in a simple way
	Well understood analysis of strength of authentication mechanism


STACK SMASHING
             
	`Smash the stack` [C programming] n. On many C implementations
	it is possible to corrupt the execution stack by writing past
	the end of an array declared auto in a routine.  Code that does
	this is said to smash the stack, and can cause return from the
	routine to jump to a random address.  This can produce some of
	the most insidious data-dependent bugs known to mankind.
	Variants include trash the stack, scribble the stack, mangle
	the stack; the term mung the stack is not used, as this is
	never done intentionally. See spam; see also alias bug,
	fandango on core, memory leak, precedence lossage, overrun screw.

INTRODUCTION
   Over the last few months there has been a large increase of buffer
overflow vulnerabilities being both discovered and exploited.  Examples
of these are syslog, splitvt, sendmail 8.7.5, Linux/FreeBSD mount, Xt 
library, at, etc.  This paper attempts to explain what buffer overflows 
are, and how their exploits work.

   Basic knowledge of assembly is required.  An understanding of virtual 
memory concepts, and experience with gdb are very helpful but not necessary.
We also assume we are working with an Intel x86 CPU, and that the operating 
system is Linux.

   Some basic definitions before we begin: A buffer is simply a contiguous 
block of computer memory that holds multiple instances of the same data 
type.  C programmers normally associate with the word buffer arrays. Most 
commonly, character arrays.  Arrays, like all variables in C, can be 
declared either static or dynamic.  Static variables are allocated at load 
time on the data segment.  Dynamic variables are allocated at run time on 
the stack. To overflow is to flow, or fill over the top, brims, or bounds. 
We will concern ourselves only with the overflow of dynamic buffers, otherwise
known as stack-based buffer overflows.


                          Process Memory Organization
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~

   To understand what stack buffers are we must first understand how a
process is organized in memory.  Processes are divided into three regions:
Text, Data, and Stack.  We will concentrate on the stack region, but first
a small overview of the other regions is in order.

   The text region is fixed by the program and includes code (instructions)
and read-only data.  This region corresponds to the text section of the
executable file.  This region is normally marked read-only and any attempt to
write to it will result in a segmentation violation.

   The data region contains initialized and uninitialized data.  Static
variables are stored in this region.  The data region corresponds to the
data-bss sections of the executable file.  Its size can be changed with the
brk(2) system call.  If the expansion of the bss data or the user stack
exhausts available memory, the process is blocked and is rescheduled to
run again with a larger memory space. New memory is added between the data
and stack segments.

                             /------------------\  lower
                             |                  |  memory
                             |       Text       |  addresses
                             |                  |
                             |------------------|
                             |   (Initialized)  |
                             |        Data      |
                             |  (Uninitialized) |
                             |------------------|
                             |                  |
                             |       Stack      |  higher
                             |                  |  memory
                             \------------------/  addresses

                         Fig. 1 Process Memory Regions


                               What Is A Stack?
                               ~~~~~~~~~~~~~~~~

   A stack is an abstract data type frequently used in computer science.  A
stack of objects has the property that the last object placed on the stack
will be the first object removed.  This property is commonly referred to as
last in, first out queue, or a LIFO.

   Several operations are defined on stacks.  Two of the most important are
PUSH and POP.  PUSH adds an element at the top of the stack.  POP, in 
contrast, reduces the stack size by one by removing the last element at the 
top of the stack.


                            Why Do We Use A Stack?
                            ~~~~~~~~~~~~~~~~~~~~~~

   Modern computers are designed with the need of high-level languages in
mind.  The most important technique for structuring programs introduced by
high-level languages is the procedure or function.  From one point of view, a
procedure call alters the flow of control just as a jump does, but unlike a
jump, when finished performing its task, a function returns control to the 
statement or instruction following the call.  This high-level abstraction
is implemented with the help of the stack.

  The stack is also used to dynamically allocate the local variables used in
functions, to pass parameters to the functions, and to return values from the
function.


                               The Stack Region
                               ~~~~~~~~~~~~~~~~

   A stack is a contiguous block of memory containing data.  A register called
the stack pointer (SP) points to the top of the stack.  The bottom of the 
stack is at a fixed address.  Its size is dynamically adjusted by the kernel 
at run time. The CPU implements instructions to PUSH onto and POP off of the 
stack. 

   The stack consists of logical stack frames that are pushed when calling a
function and popped when returning.  A stack frame contains the parameters to 
a function, its local variables, and the data necessary to recover the 
previous stack frame, including the value of the instruction pointer at the 
time of the function call.

   Depending on the implementation the stack will either grow down (towards
lower memory addresses), or up.  In our examples we'll use a stack that grows
down.  This is the way the stack grows on many computers including the Intel, 
Motorola, SPARC and MIPS processors.  The stack pointer (SP) is also
implementation dependent.  It may point to the last address on the stack, or 
to the next free available address after the stack.  For our discussion we'll
assume it points to the last address on the stack.

   In addition to the stack pointer, which points to the top of the stack
(lowest numerical address), it is often convenient to have a frame pointer
(FP) which points to a fixed location within a frame.  Some texts also refer
to it as a local base pointer (LB).  In principle, local variables could be
referenced by giving their offsets from SP.  However, as words are pushed onto
the stack and popped from the stack, these offsets change.  Although in some
cases the compiler can keep track of the number of words on the stack and
thus correct the offsets, in some cases it cannot, and in all cases
considerable administration is required.  Futhermore, on some machines, such
as Intel-based processors, accessing a variable at a known distance from SP
requires multiple instructions.

   Consequently, many compilers use a second register, FP, for referencing
both local variables and parameters because their distances from FP do
not change with PUSHes and POPs.  On Intel CPUs, BP (EBP) is used for this 
purpose.  On the Motorola CPUs, any address register except A7 (the stack 
pointer) will do.  Because the way our stack grows, actual parameters have 
positive offsets and local variables have negative offsets from FP.

   The first thing a procedure must do when called is save the previous FP
(so it can be restored at procedure exit).  Then it copies SP into FP to 
create the new FP, and advances SP to reserve space for the local variables. 
This code is called the procedure prolog.  Upon procedure exit, the stack 
must be cleaned up again, something called the procedure epilog.  The Intel 
ENTER and LEAVE instructions and the Motorola LINK and UNLINK instructions, 
have been provided to do most of the procedure prolog and epilog work 
efficiently. 

   Let us see what the stack looks like in a simple example:

example1.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
}

void main() {
  function(1,2,3);
}
------------------------------------------------------------------------------

   To understand what the program does to call function() we compile it with
gcc using the -S switch to generate assembly code output:

$ gcc -S -o example1.s example1.c

   By looking at the assembly language output we see that the call to
function() is translated to:

        pushl $3
        pushl $2
        pushl $1
        call function

    This pushes the 3 arguments to function backwards into the stack, and
calls function().  The instruction 'call' will push the instruction pointer
(IP) onto the stack.  We'll call the saved IP the return address (RET).  The
first thing done in function is the procedure prolog:

        pushl %ebp
        movl %esp,%ebp
        subl $20,%esp

   This pushes EBP, the frame pointer, onto the stack.  It then copies the
current SP onto EBP, making it the new FP pointer.  We'll call the saved FP
pointer SFP.  It then allocates space for the local variables by subtracting
their size from SP.

   We must remember that memory can only be addressed in multiples of the
word size.  A word in our case is 4 bytes, or 32 bits.  So our 5 byte buffer
is really going to take 8 bytes (2 words) of memory, and our 10 byte buffer
is going to take 12 bytes (3 words) of memory.  That is why SP is being
subtracted by 20.  With that in mind our stack looks like this when
function() is called (each space represents a byte):


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]
	   
top of                                                            bottom of
stack                                                                 stack


                               Buffer Overflows
                               ~~~~~~~~~~~~~~~~

   A buffer overflow is the result of stuffing more data into a buffer than
it can handle.  How can this often found programming error can be taken
advantage to execute arbitrary code?  Lets look at another example:

example2.c
------------------------------------------------------------------------------
void function(char *str) {
   char buffer[16];

   strcpy(buffer,str);
}

void main() {
  char large_string[256];
  int i;

  for( i = 0; i < 255; i++)
    large_string[i] = 'A';

  function(large_string);
}
------------------------------------------------------------------------------

   This is program has a function with a typical buffer overflow coding
error.  The function copies a supplied string without bounds checking by
using strcpy() instead of strncpy().  If you run this program you will get a
segmentation violation.  Lets see what its stack looks when we call function:


bottom of                                                            top of
memory                                                               memory
                  buffer            sfp   ret   *str
<------          [                ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   What is going on here?  Why do we get a segmentation violation?  Simple.
strcpy() is coping the contents of *str (larger_string[]) into buffer[]
until a null character is found on the string.  As we can see buffer[] is
much smaller than *str.  buffer[] is 16 bytes long, and we are trying to stuff
it with 256 bytes.  This means that all 250 bytes after buffer in the stack
are being overwritten.  This includes the SFP, RET, and even *str!  We had 
filled large_string with the character 'A'.  It's hex character value
is 0x41.  That means that the return address is now 0x41414141.  This is
outside of the process address space.  That is why when the function returns
and tries to read the next instruction from that address you get a 
segmentation violation.

   So a buffer overflow allows us to change the return address of a function.
In this way we can change the flow of execution of the program.  Lets go back
to our first example and recall what the stack looked like:


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   Lets try to modify our first example so that it overwrites the return
address, and demonstrate how we can make it execute arbitrary code.  Just
before buffer1[] on the stack is SFP, and before it, the return address.
That is 4 bytes pass the end of buffer1[].  But remember that buffer1[] is
really 2 word so its 8 bytes long.  So the return address is 12 bytes from
the start of buffer1[].  We'll modify the return value in such a way that the
assignment statement 'x = 1;' after the function call will be jumped.  To do
so we add 8 bytes to the return address.  Our code is now:

example3.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
   int *ret;

   ret = buffer1 + 12;
   (*ret) += 8;
}

void main() {
  int x;

  x = 0;
  function(1,2,3);
  x = 1;
  printf("%d\n",x);
}
------------------------------------------------------------------------------

   What we have done is add 12 to buffer1[]'s address.  This new address is
where the return address is stored.  We want to skip pass the assignment to
the printf call.  How did we know to add 8 to the return address?  We used a
test value first (for example 1), compiled the program, and then started gdb:

------------------------------------------------------------------------------
[aleph1]$ gdb example3
GDB is free software and you are welcome to distribute copies of it
 under certain conditions; type "show copying" to see the conditions.
There is absolutely no warranty for GDB; type "show warranty" for details.
GDB 4.15 (i586-unknown-linux), Copyright 1995 Free Software Foundation, Inc...
(no debugging symbols found)...
(gdb) disassemble main
Dump of assembler code for function main:
0x8000490 <main>:       pushl  %ebp
0x8000491 <main+1>:     movl   %esp,%ebp
0x8000493 <main+3>:     subl   $0x4,%esp
0x8000496 <main+6>:     movl   $0x0,0xfffffffc(%ebp)
0x800049d <main+13>:    pushl  $0x3
0x800049f <main+15>:    pushl  $0x2
0x80004a1 <main+17>:    pushl  $0x1
0x80004a3 <main+19>:    call   0x8000470 <function>
0x80004a8 <main+24>:    addl   $0xc,%esp
0x80004ab <main+27>:    movl   $0x1,0xfffffffc(%ebp)
0x80004b2 <main+34>:    movl   0xfffffffc(%ebp),%eax
0x80004b5 <main+37>:    pushl  %eax
0x80004b6 <main+38>:    pushl  $0x80004f8
0x80004bb <main+43>:    call   0x8000378 <printf>
0x80004c0 <main+48>:    addl   $0x8,%esp
0x80004c3 <main+51>:    movl   %ebp,%esp
0x80004c5 <main+53>:    popl   %ebp
0x80004c6 <main+54>:    ret
0x80004c7 <main+55>:    nop
------------------------------------------------------------------------------

   We can see that when calling function() the RET will be 0x8004a8, and we
want to jump past the assignment at 0x80004ab.  The next instruction we want
to execute is the at 0x8004b2.  A little math tells us the distance is 8
bytes.


                                  Shell Code
                                  ~~~~~~~~~~

   So now that we know that we can modify the return address and the flow of
execution, what program do we want to execute?  In most cases we'll simply
want the program to spawn a shell.  From the shell we can then issue other
commands as we wish.  But what if there is no such code in the program we
are trying to exploit?  How can we place arbitrary instruction into its
address space?  The answer is to place the code with are trying to execute in
the buffer we are overflowing, and overwrite the return address so it points
back into the buffer.  Assuming the stack starts at address 0xFF, and that S
stands for the code we want to execute the stack would then look like this:


bottom of  DDDDDDDDEEEEEEEEEEEE  EEEE  FFFF  FFFF  FFFF  FFFF     top of
memory     89ABCDEF0123456789AB  CDEF  0123  4567  89AB  CDEF     memory
           buffer                sfp   ret   a     b     c

<------   [SSSSSSSSSSSSSSSSSSSS][SSSS][0xD8][0x01][0x02][0x03]
           ^                            |
           |____________________________|
top of                                                            bottom of
stack                                                                 stack


The code to spawn a shell in C looks like:

shellcode.c
-----------------------------------------------------------------------------
#include <stdio.h>

void main() {
   char *name[2];

   name[0] = "/bin/sh";
   name[1] = NULL;
   execve(name[0], name, NULL);
}
------------------------------------------------------------------------------

   To find out what does it looks like in assembly we compile it, and start
up gdb.  Remember to use the -static flag. Otherwise the actual code the
for the execve system call will not be included.  Instead there will be a
reference to dynamic C library that would normally would be linked in at
load time.

------------------------------------------------------------------------------
[aleph1]$ gcc -o shellcode -ggdb -static shellcode.c





ANDROID SECURITY
App review before distribution -iOS: Apple manual and automated vetting; Android -  Easier to get app placed on market,Transparent automated scanning, removal via Bouncer
App isolation and protection - Sandboxing and restricted permission ;Android - Permission model ( runtime, dangerous/ normal) ,Defense against circumvention.
ANDROID CORE SECURITY FEATURES:
•	The Android Application Sandbox, isolates app data and code execution from other apps.
•	App framework with Implementations of common security functionality such as cryptography, permissions, and secure IPC.
•	Technologies like ASLR, NX, ProPolice, safe_iop, OpenBSD dlmalloc, OpenBSD calloc, and Linux mmap_min_addr to mitigate risks associated with common memory management errors.
•	An encrypted file system that can be enabled
•	User-granted permissions to restrict access to system features and user data.
•	Application-defined permissions to control application data on a per-app basis.
THREATS TO MOBILE APPLICATIONS:
•	Privacy: Data leakage, identifier leakage, third-party tags and libraries, location privacy
•	Security: Phishing, malware & drive-bys, malicious intents on Android, Ikee/Zitmo and other mobile malware.
OWASP Mobile Top Ten:
M1This category covers misuse of a platform feature or failure to use platform security controls. It might include Android intents, platform permissions, misuse of TouchID, the Keychain, or some other security control that is part of the mobile operating system. There are several ways that mobile apps can experience this risk.
M2: This new category is a combination of M2 + M4 from Mobile Top Ten 2014. This covers insecure data storage and unintended data leakage.
M3: This covers poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
M4: This category captures notions of authenticating the end user or bad session management. This can include:
Failing to identify the user at all when that should be required
Failure to maintain the user's identity when it is required
Weaknesses in session management
M5: Insufficient Cryptography : wrong crypto usage 
M6: Insecure Authorization
M7: Client Code Quality Issues : client side eg buffer overflows 
M8: Code Tampering : attacker nodification (code, memory etc) 
M9: Reverse Engineering : by attacker and gaining info 
M10: Extraneous Functionality : hidden back door or password in comment by mistake etc .
•	M1: misuse of a platform feature or failure to use platform security controls. egAndroid intents, platform permissions, misuse of TouchID, the Keychain, or some other security control 
•	M2: covers insecure data storage and unintended data leakage.
•	M3: poor handshaking, incorrect SSL versions, weak negotiation, cleartext communication of sensitive assets, etc.
•	M4: authenticating end user or bad session management. This can include:Failing to identify the user at all when that should be required, Failure to maintain the user's identity when it is required. Weaknesses in session management.
MOBILE MALWARE EXAMPLES:
•	DroidDream (Android)
o	Over 58 apps uploaded to Google app market
o	Conducts data theft; send credentials to attacker
o	Trozan, gained root access
•	Ikee (iOS)
o	Worm capabilities (targeted default ssh pwd)
o	Worked only on jailbroken phones with ssh installed 
o	Zitmo (Symbian,BlackBerry,Windows,Android)
o	Propagates via SMS; claims to install a “security certificate”
o	Captures info from SMS; aimed at defeating 2-factor auth 
o	Works with Zeus botnet; timed with user PC infection.
COMPARISON BETWEEN PLATFORMS: 
•	Approval process for applications
o	Market: Vendor controlled/Open
o	App signing: Vendor-issued/self-signed
o	User approval of permission
•	Programming language for applications
o	Managed execution: Java, .Net 
o	Native execution: Objective C0.
ANDROID:
•	Platform outline:
o	Linux kernel, browser, SQL-lite database
o	Software for secure network communication
	Open SSL, Bouncy Castle crypto API and Java library 
o	C language infrastructure
o	Java platform for running applications
	Dalvik bytecode, virtual machine
                              ,         

ANDROID MARKET:
•	Self-signed apps
•	App permissions granted on user installation
•	Open market -  Bad applications may show up on market;Shifts focus from remote exploit to privilege escalation.
ANDROID PERMISSIONS:
•	Example of permissions provided by Android
o	“android.permission.INTERNET”
o	“android.permission.READ_EXTERNAL_STORAGE 
o	“android.permission.SEND_SMS”
o	“android.permission.BLUETOOTH” 
•	Also possible to define custom permissions
ANDROID PERMISSION MODEL:
Google maps or Uber asking for location permission to be switched on.
 
 
SECURITY FEATURES:
•	Isolation
o	Multi-user Linux operating system 
o	Each application normally runs as a different user
•	Communication between applications
o	May share same Linux user ID
	Access files from each other
	May share same Linux process and Dalvik VM
o	Communicate through application framework
	“Intents,” based on Binder, discussed in a few slides
•	Battery life
o	Developers must conserve power
o	Applications store state so they can be stopped (to save power) and restarted.
APPLICATION  SANDBOX:
o	Each application runs with its UID in its own Dalvik virtual machine
	Provides CPU protection, memory protection
	Authenticated communication protection using Unix domain sockets
	Only ping, zygote (spawn another process) run as root
o	Applications announce permission requirement
	Create a whitelist model – user grants access
	Don’t interrupt user  – all questions asked as install time
	Inter-component communication reference monitor checks permissions.
EXPLOIT PREVENTION:
	Open source: public review, no obscurity
	Goals
o	Prevent remote attacks, privilege escalation
o	Secure drivers, media codecs, new and custom features
	Overflow prevention
o	ProPolice stack protection
	First on the ARM architecture
o	Some heap overflow protections
	Chunk consolidation in DL malloc (from OpenBSD)
	ASLR (Address Space Layout Randomisation) 
o	Avoided in initial release
	Many pre-linked images for performance 
o	Later developed and contributed by Bojinov, Boneh.
DLMALLOC: 
	Stores meta data in band 
	Heap consolidation attack
o	Heap overflow can overwrite pointers to previous and next unconsolidated chunks
o	Overwriting these pointers allows remote code execution
	Change to improve security
o	Check integrity of forward and backward pointers
	Simply check that back-forward-back = back,  f-b-f=f
o	Increases the difficulty of heap overflow
APPLICATION DEVELOPMENT CONCEPTS:
	Activity – one-user task
o	Example: scroll through your inbox
o	Email client comprises many activities
	Service – Java daemon that runs in background
o	Example: application that streams an mp3 in background
	Intents – asynchronous messaging system
o	Fire an intent to switch from one activity to another
o	Example: email app has inbox, compose activity, viewer activity
	User click on inbox entry fires an intent to the viewer activity, which then allows user to view that email
	Content provider
o	Store and share data using a relational database interface 
	Broadcast receiver
o	 “mailboxes” for messages from other applications
ANDROID INTENTS: 
	Message between components in same or different app
	Intent is a bundle of information, e.g.,  
o	action to be taken
o	data to act on
o	category of component to handle the intent
o	instructions on how to launch a target activity
	Routing can be
o	Explicit: delivered only to a specific receiver 
o	Implicit: all components that have registered to receive that action will get the message
 
 
SECURITY ISSUES WITH INTENTS:
	Sender of an intent can verify that the recipient has a permission by specifying a permission with the method call
	Senders can use explicit intents to send the message to a single component (avoiding broadcasting)
	Receivers have to handle malicious intents
ATTACK : PERMISSION REDELEGATION
	Definition: an application without a permission gains additional privileges through another application 
	Example of the “confused deputy” problem 
   
	App w/ permissions exposes a public interface
	Study in 2011
o	Examine 872 apps
o	320 of these (37%) have permissions and at least one type of public component
o	Construct attacks using 15 vulnerabilities in 5 apps
POWER CONTROL WIDGET:
	Can change Wi-fi, BT, GPS, Data Sync, Screen Brightness with only one click 
	Uses Intent to communicate the event of switching settings
A malicious app without permissions can send a fake Intent to the Power Control Widget, simulating click to switch settings
Principle of least privilege works but is not a solution. Apps with permissions need to manage security.
JAVA SANDBOX:
	Four complementary mechanisms
o	Class loader
	Separate namespaces for separate class loaders
	Associates protection domain with each class 
o	Verifier and JVM run-time tests
	NO unchecked casts or other type errors, NO array overflow
	Preserves private, protected visibility levels
o	Security Manager
	Called by library functions to decide if request is allowed
	Uses protection domain associated with code, user policy
STACK INSPECTION: 
•	Permission depends on
o	Permission of calling method
o	Permission of all methods above it on stack
	Up to method that is trusted and asserts this trust 
MAC OS APPLICATION DEVELOPMENT:
•	Apps developed in Objective-C using Apple SDK
•	model based on touch events
•	FoundEvent-handling ation and UIKit frameworks provide the key services used by all iOS applications



MAC OS PLATFORM:
 

 

APP SECURITY:
•	Runtime protection
o	System resources, kernel shielded from user apps
o	App “sandbox” prevents access to other app’s data 
o	Inter-app communication only through iOS APIs 
o	Code generation prevented
•	Mandatory code signing
o	All apps must be signed using Apple-issued certificate
•	Application data protection
o	Apps can leverage built-in hardware encryption
IOS SANDBOX:
•	Limit app’s access to files, preferences, network, other resources
•	Each app has own sandbox directory
•	Limits consequences of attacks
•	Same privileges for each app
FILE ENCRYPTION:
•	The content of a file is encrypted with a per-file key, which is wrapped with a class key and stored in a file’s metadata, which is in turn encrypted with the file system key. 
o	When a file is opened, its metadata is decrypted with the file system key, revealing the wrapped per-file key and a notation on which class protects it 
o	The per-file key is unwrapped with the class key, then supplied to the hardware AES engine, decrypting the file as it is read from flash memory
•	The metadata of all files is encrypted with a random key. Since it’s stored on the device, used only for quick erased on demand.
 
MASQUE ATTACK:
•	iOS app installed using enterprise/ad-hoc provisioning could replace genuine app installed through the App Store, if both apps have same bundle identifier
•	This vulnerability existed because iOS didn't enforce matching certificates for apps with the same bundle identifier 
COMPARISON OF MAC OS VS ANDROID:
•	App approval process
o	Android apps from open app store
o	iOS vendor-controlled store of vetted apps
•	Application permissions
o	Android permission based on install-time manifest
o	All iOS apps have same set of “sandbox” privileges
•	App programming language
o	Android apps written in Java; no buffer overflow…
o	iOS apps written in Objective-C
	iOS	Android	Windows
Unix	x	x	
Windows			
Open market		x	
Closed market	x		
Vendor signed	x		
Self-signed		x	
User approval of permissions		x	
Managed code		x	
Native code	x		

MOST SIGNIFICANT VULNERABILITIES:
	Loading untrusted web content
	Leaking URLs to foreign apps
	Exposing state changing navigation to foreign apps


BUFFER OVERFLOW
EXPLANATION FOR LAST PROGRAM:
Figure 11.12a illustrates such a vulnerable program (which shares many similarities with Figure 11.11a, except that the structure is declared as a global variable). The design of the attack is very similar, indeed only the target address changes. The global structure was found to be at address 0x08049740, which was used as the target address in the attack. Note that global variables do not usually change location, as their addresses are used directly in the program code. The attack script and result of successfully executing it are shown in the text in Figure 11.12b.
MALICIOUS SOFTWARE:
	programs exploiting system vulnerabilities
	known as malicious software or malware 
o	program fragments that need a host program
	e.g. viruses, logic bombs, and backdoors 
o	independent self-contained programs
	e.g. worms, bots
o	replicating or not
	sophisticated threat to computer systems

MALWARE TECHNOLOGY:
	Mobile code software : can be shipped unchanged to a heterogeneous collection of platforms and execute with identical semantics
	Auto-rooter malicious hacker tools : used to break into new machines remotely Kit (virus generator) Set of tools for generating new viruses automatically 
	Spammer and Flooder programs : used to send large volumes of unwanted e-mail, or to attack systems with a large volumes of traffic to carry out a DoS attack.
VIRUS:
	piece of software that infects programs
o	modifying them to include a copy of the virus
o	so it executes secretly when host program is run
	specific to operating system and hardware
o	taking advantage of their details and weaknesses
	a typical virus goes through phases of:
o	dormant
o	propagation
o	triggering
o	execution
Email Viruses
A more recent development in malicious software is the e-mail virus. The first rapidly spreading e-mail viruses, such as Melissa, made use of a Microsoft Word macro embedded in an attachment. If the recipient opens the e-mail attachment, the Word macro is activated. Then the e-mail virus sends itself to everyone on the mailing list in the user's e-mail package, and also does local damage.
At the end of 1999, a more powerful version of the e-mail virus appeared. This newer version can be activated merely by opening an e-mail that contains the virus rather than opening an attachment. The virus uses the Visual Basic scripting language supported by the e-mail package.
Thus we see a new generation of malware that arrives via e-mail and uses e-mail software features to replicate itself across the Internet. The virus propagates itself as soon as activated (either by opening an e-mail attachment of by opening the e-mail) to all of the e-mail addresses known to the infected host. As a result, whereas viruses used to take months or years to propagate, they now do so in hours. This makes it very difficult for antivirus software to respond before much damage is done. Ultimately, a greater degree of security must be built into Internet utility and application software on PCs to counter the growing threat.
DIGITAL IMMUNE SYSTEM:
Comprehensive approach to virus protection developed by IBM and subsequently refined by Symantec
When a new virus enters an organization, the immune system automatically captures it, analyzes it, adds detection and shielding for it, removes it, and passes information about that virus to other systems so that it can be detected before it is allowed to run elsewhere
	1. A monitoring program on each PC uses a variety of heuristics to infer that a virus may be present, and forwards a copy to an administrative machine.
	2. The admin machine encrypts this and sends it to a central virus analysis machine.
	3. This machine creates an environment in which the infected program can be safely run for analysis. The virus analysis machine then produces a prescription for identifying and removing the virus.
	 4. The resulting prescription is sent back to the administrative machine. 
	5.  The administrative machine forwards the prescription to the infected client.
	 6. The prescription is also forwarded to other clients in the organization.
	 7. Subscribers worldwide receive regular antivirus updates to protect from new virus
The success of the digital immune system depends on the ability of the virus analysis machine to detect new and innovative virus strains.

  
 
BEHAVIOURAL BLOCKING SOFTWARE:
Unlike heuristics or fingerprint-based scanners, behavior-blocking software integrates with the operating system of a host computer and monitors program behavior in real-time for malicious actions. The behavior blocking software then blocks potentially malicious actions before they can affect the system. Monitored behaviors can include
• Attempts to open, view, delete, and/or modify files;
• Attempts to format disk drives and other unrecoverable disk operations;
• Modifications to the logic of executable files or macros;
• Modification of critical system settings, such as start-up settings;
• Scripting of e-mail and instant messaging clients to send executable content; and
• Initiation of network communications.
Figure 7.5 illustrates its operation. Behavior-blocking software runs on server and desktop computers and is instructed through policies set by the network administrator to let benign actions take place but to intercede when unauthorized or suspicious actions occur. The module blocks any suspicious software from executing. A blocker isolates the code in a sandbox, which restricts the code's access to various OS resources and applications. The blocker then sends an alert. Because behavior blocker can block suspicious software in real-time, it has an advantage over such established antivirus detection techniques as fingerprinting or heuristics. Behavior blocking alone has limitations. Because the malicious code must run on the target machine before all its behaviors can be identified, it can cause harm before it has been detected and blocked. 
MORRIS WORM: Until the current generation of worms, the best known was the worm released onto the Internet by Robert Morris in 1988. The Morris worm was designed to spread on UNIX systems and used a number of different techniques for propagation. When a copy began execution, its first task was to discover other hosts known to this host that would allow entry from this host. The worm performed this task by examining a variety of lists and tables, including system tables that declared which other machines were trusted by this host, users' mail forwarding files, tables by which users gave themselves permission for access to remote accounts, and from a program that reported the status of network connections. For each discovered host, the worm tried a number of methods for gaining access:
1.	 It attempted to log on to a remote host as a legitimate user, having cracked the local password file, and assuming that many users use the same password on different systems. 
2.	 It exploited a bug in the finger protocol
3.	It exploited a trapdoor in the debug option of the remote sendmail process.
If any of these attacks succeeded, the worm achieved communication with the operating system command interpreter. It then sent this interpreter a short bootstrap program, issued a command to execute that program, and then logged off. The bootstrap program then called back the parent program and downloaded the remainder of the worm. The new worm was then executed.
WORM COUNTERMEASURES:
There is considerable overlap in techniques for dealing with viruses and worms. Once a worm is resident on a machine, antivirus software can be used to detect it. In addition, because worms propagation generates considerable network activity, the monitoring of that activity can lead form the basis of a worm defense. Have classes: 
A.	Signature-based worm scan filtering: generates a worm signature, which is then used to prevent worm scans from entering/leaving a network/host. 
B.	Filter-based worm containment: focuses on worm content rather than a scan signature. The filter checks a message to determine if it contains worm code.
C.	Payload-classification-based worm containment: examine packets to see if they contain a worm using anomaly detection techniques 
D.	Threshold random walk (TRW) scan detection: exploits randomness in picking destinations to connect to as a way of detecting if a scanner is in operation 
E.	Rate limiting: limits the rate of scanlike traffic from an infected host. 
F.	Rate halting: immediately blocks outgoing traffic when a threshold is exceeded either in outgoing connection rate or diversity of connection attempts. Rate halting can integrate with a signature- or filter-based approach so that once a signature or filter is generated, every blocked host can be unblocked; as with rate limiting, rate halting techniques are not suitable for slow, stealthy worms. 

PROACTIVE WORM CONTAINMENT:
The Proactive Worm Containment (PWC) scheme is host based software that looks for surges in the rate of frequency of outgoing connection attempts and the diversity of connections to remote hosts. When such a surge is detected, the software immediately blocks its host from further connection attempts. A deployed PWC system consists of a PWC manager and PWC agents in hosts. Figure 7.7 from the text is an example of an architecture that includes PWC, which operates as detailed: 
A.	 A PWC agent monitors outgoing traffic for scan activity, determined by a surge in UDP / TCP connection attempts to remote hosts. If a surge is detected, the agent: 1) issues an alert to local system; 2) blocks all outgoing connection attempts; 3) transmits the alert to the PWC manager; and  4) starts a relaxation analysis. 
B. A PWC manager receives an alert, and propagates the alert to all other agents.
C. The host receives an alert, and must decide whether to ignore the alert. If the time since the last incoming packet has been sufficiently long so that the agent would have detected a worm if infected, then the alert is ignored. Otherwise, the agent assumes that it might be infected and performs the following actions:(1) blocks all outgoing connection attempts from the specific alerting port;and (2) starts a relaxation analysis. 
D. Relaxation analysis. An agent monitors outgoing activity for a fixed window of time to see if outgoing connections exceed a threshold. If so, blockage is continued and relaxation analysis is repeated until the outgoing connection rate drops below the threshold, at which time the agent removes the block. If the threshold continues to be exceeded over a sufficient number of relaxation windows, the agent isolates the host and reports to the PWC manager. 
Meanwhile, a signature extractor functions as a passive sensor that monitors all traffic and attempts to detect worms by signature analysis. 

NETWORK BASED WORM DEFENSE
The key element of a network-based worm defense is worm monitoring software. Two types of monitoring software are needed: 
• Ingress monitors: located at the border between the enterprise network and the Internet, in a border router, external firewall, separate passive monitor, or honeypot.
• Egress monitors: located at the egress point of individual LANs on the enterprise network as well as at the external border, in a LAN router or switch, external firewall or honeypot. The two types of monitors can be collocated. It is designed to catch the source of a worm attack by monitoring outgoing traffic for signs of scanning etc.
Worm monitors can act in the manner of intrusion detection systems and generate alerts to a central administrative system. It is also possible to implement a system that attempts to react in real time to a worm attack, so as to counter zero-day exploits effectively. This is similar to the approach taken with the digital immune system (Figure 7.4). Figure 7.8 shows an example of a worm countermeasure architecture that works as :
1.	Sensors deployed at various network locations detect a potential worm.
2. and send alerts to a central server that correlates / analyzes incoming alerts.
3. forwards info to a protected environment, where worm is sandboxed for analysis 
4. protected system tests the suspicious software against an appropriately instrumented version of the targeted application to identify the vulnerability. 
5. protected system generates one or more software patches and tests these.
6. system sends the patch to the application host to update the targeted application. 

INTERNET SECURITY PROTOCOLS AND STANDARDS
IPSec ensures TCP and application protocol is encrypted – and much of IP too.
With SSL or TLS, IP and TCP are not encrypted.
Benefits in routing applications:
	A routing advertisement : comes from an authorised router
	A neighbour advertisement
	A redirect message comes from router to which initial message was sent
	A routing update is not forged
	An ICMP redirect is an error message sent by a router to the sender of an IP packet . Redirects are used when a router believes a packet is being routed sub optimally and it would like to inform the sending host that it should forward subsequent packets to that same destination through a different gateway.
 

 
AUTHENTICATION HEADER: The Authentication Header provides support for data integrity and authentication of IP packets.The data integrity feature ensures that undetected modification to a packet’s content in transit is not possible. The authentication feature enables an end system or network device to authenticate the user or application and filter traffic accordingly; it also prevents address spoofing attacks and replay attacks. Authentication is based on the use of a message authentication code (MAC), hence the two parties must share a secret key. AH supports MACs using HMAC-MD5-96 or HMAC-SHA-1-96. Both of these use the HMAC algorithm , the first with the MD5 hash code and the second with the SHA-1 hash code. In both cases, the full HMAC value is calculated but then truncated by using the first 96-bits, which is the default length for the Authentication Data field.
ENCAPSULATION SECURITY PAYLOAD  (ESP):
	Provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality 
	As an optional feature, ESP can also provide an authentication service, with the same MACs as AH
	Padding used based on need on encryption algorithm used, also used for limited data confidentiality by concealing actual length of flow
 
Figure 21.4 shows the Authentication Header fields:
• Next Header (8 bits): Identifies the type of header immediately following this header
• Payload Length (8 bits): Length of Authentication Header in 32-bit words, minus 2. 
• Reserved (16 bits): For future use
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value
• Authentication Data (variable): A variable-length field (must be an integral number of 32-bit words) that contains the Integrity Check Value (ICV), or MAC,for this packet
The authentication data field is calculated over
• IP header fields that either do not change in transit (immutable) or that are predictable in value upon arrival at the endpoint for the AH SA. 
• The AH header other than the Authentication Data field. The Authentication Data field is set to zero for purposes of calculation at both source and destination. 
• The entire upper-level protocol data, which is assumed to be immutable in transit.

ENCAPSULATION SECURITY PAYLOAD:

The Encapsulating Security Payload provides confidentiality services, including confidentiality of message contents and limited traffic flow confidentiality. As an optional feature, ESP can also provide an authentication service, with the same MACs as AH. ESP supports range of ciphers, modes, and padding, as shown.
 Figure 21.5 shows the format of an ESP packet. It contains the following fields:
• Security Parameters Index (32 bits): Identifies a security association
• Sequence Number (32 bits): A monotonically increasing counter value; this provides an anti-replay function ,as discussed for AH
• Payload Data (variable): This is a transport-level segment (transport mode) or IP packet (tunnel mode) that is protected by encryption
• Padding (0–255 bytes): for various reasons
• Pad Length (8 bits): Indicates the number of pad bytes immediately preceding this field
• Next Header (8 bits): Identifies the type of data contained in the payload data field by identifying the first header in that payload 
• Authentication Data (variable): A variable-length field that contains the Integrity Check Value computed over the ESP packet minus the Authentication Data field 
TRANSPORT VS TUNNEL MODE:
Stallings Figure 16.5 shows the difference between end-to-end (transport) mode and end-to-intermediate (tunnel) mode.
Transport mode provides protection primarily for upper-layer protocol payloads, by inserting the AH after the original IP header and before the IP payload. Typically, transport mode is used for end-to-end communication between two hosts.
Tunnel mode provides protection to the entire IP, after the AH or ESP fields are added to the IP packet, the entire packet plus security fields is treated as the payload of new “outer”IP packet with a new outer IP header. Tunnel mode is used when one or both ends of an SA are a security gateway, such as a firewall or router that implements IPSec. 


 
 

 
KEY MANAGEMENT:
The key management portion of IPSec involves the determination and distribution of secret keys. A typical requirement is four keys for communication between two applications: transmit and receive pairs for both AH and ESP. The IPSec Architecture document mandates support for two types of key management:
• Manual where a system administrator manually configures each system with its own keys and with the keys of other communicating 
• Automated where an automated system enables the on-demand creation of keys for SAs and facilitates the use of keys in a large distributed system with an evolving configuration
The default automated key management protocol for IPSec is referred to as ISAKMP/Oakley.
Default Key Management protocol for IPSEC is ISAKMP/Oakley. Following elements
	Oakley Key Determination protocol : Based on Diffie-Hellman algorithm but providing added security to avoid man in middle attack
	Internet Security Association and Key Management Protocol (ISAKMP) Framework for Internet Key management and provides specific protocol support 


PUBLIC KEY ENCRYPTION:
Main Characteristics or differentiating factors
	Digest Length
	Basic Unit of processing ( input block length )
	Number of steps
	Maximum message size
	Number of primitive logical functions
	Number of additive constants used
HMAC: In recent years, there has been increased interest in developing a MAC derived from a cryptographic hash code, such as SHA-1, since these are usually faster, and code is widely available. A hash function such as SHA-1 was not designed for use as a MAC and cannot be used directly for that purpose because it does not rely on a secret key. There have been a number of proposals for the incorporation of a secret key into an existing hash algorithm. The approach that has received the most support is HMAC. 
HMAC has been issued as RFC 2104, has been chosen as the mandatory-to-implement MAC for IP Security, and is used in other Internet protocols, such as Transport Layer Security (TLS, soon to replace Secure Sockets Layer) and Secure Electronic Transaction (SET). HMAC treats the hash function as a "black box." This has two benefits. First, an existing implementation of a hash function can be used as a module in implementing HMAC. In this way, the bulk of the HMAC code is prepackaged and ready to use without modification. Second, if it is ever desired to replace a given hash function in an HMAC implementation, all that is required is to remove the existing hash function module and drop in the new module. This could be done if a faster hash function were desired. More important, if the security of the embedded hash function were compromised, the security of HMAC could be retained simply by replacing the embedded hash function with a more secure one. Also, HMAC can be proven secure provided that the embedded hash function has some reasonable cryptographic strengths. 
CRYPTOGRAPHIC HASH FUNCTION – HMAC :
Design Objectives
	Developing MAC from Cryptographic hash code ( relies on secret key)
	To be able to use existing hash functions without modification
	Allow easy replaceability of embedded hash function in case faster or more secure functions are found
	No degradation on performance from original hash function
	Handle keys in a simple way
	Well understood analysis of strength of authentication mechanism


STACK SMASHING
             
	`Smash the stack` [C programming] n. On many C implementations
	it is possible to corrupt the execution stack by writing past
	the end of an array declared auto in a routine.  Code that does
	this is said to smash the stack, and can cause return from the
	routine to jump to a random address.  This can produce some of
	the most insidious data-dependent bugs known to mankind.
	Variants include trash the stack, scribble the stack, mangle
	the stack; the term mung the stack is not used, as this is
	never done intentionally. See spam; see also alias bug,
	fandango on core, memory leak, precedence lossage, overrun screw.

INTRODUCTION
   Over the last few months there has been a large increase of buffer
overflow vulnerabilities being both discovered and exploited.  Examples
of these are syslog, splitvt, sendmail 8.7.5, Linux/FreeBSD mount, Xt 
library, at, etc.  This paper attempts to explain what buffer overflows 
are, and how their exploits work.

   Basic knowledge of assembly is required.  An understanding of virtual 
memory concepts, and experience with gdb are very helpful but not necessary.
We also assume we are working with an Intel x86 CPU, and that the operating 
system is Linux.

   Some basic definitions before we begin: A buffer is simply a contiguous 
block of computer memory that holds multiple instances of the same data 
type.  C programmers normally associate with the word buffer arrays. Most 
commonly, character arrays.  Arrays, like all variables in C, can be 
declared either static or dynamic.  Static variables are allocated at load 
time on the data segment.  Dynamic variables are allocated at run time on 
the stack. To overflow is to flow, or fill over the top, brims, or bounds. 
We will concern ourselves only with the overflow of dynamic buffers, otherwise
known as stack-based buffer overflows.


                          Process Memory Organization
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~

   To understand what stack buffers are we must first understand how a
process is organized in memory.  Processes are divided into three regions:
Text, Data, and Stack.  We will concentrate on the stack region, but first
a small overview of the other regions is in order.

   The text region is fixed by the program and includes code (instructions)
and read-only data.  This region corresponds to the text section of the
executable file.  This region is normally marked read-only and any attempt to
write to it will result in a segmentation violation.

   The data region contains initialized and uninitialized data.  Static
variables are stored in this region.  The data region corresponds to the
data-bss sections of the executable file.  Its size can be changed with the
brk(2) system call.  If the expansion of the bss data or the user stack
exhausts available memory, the process is blocked and is rescheduled to
run again with a larger memory space. New memory is added between the data
and stack segments.

                             /------------------\  lower
                             |                  |  memory
                             |       Text       |  addresses
                             |                  |
                             |------------------|
                             |   (Initialized)  |
                             |        Data      |
                             |  (Uninitialized) |
                             |------------------|
                             |                  |
                             |       Stack      |  higher
                             |                  |  memory
                             \------------------/  addresses

                         Fig. 1 Process Memory Regions


                               What Is A Stack?
                               ~~~~~~~~~~~~~~~~

   A stack is an abstract data type frequently used in computer science.  A
stack of objects has the property that the last object placed on the stack
will be the first object removed.  This property is commonly referred to as
last in, first out queue, or a LIFO.

   Several operations are defined on stacks.  Two of the most important are
PUSH and POP.  PUSH adds an element at the top of the stack.  POP, in 
contrast, reduces the stack size by one by removing the last element at the 
top of the stack.


                            Why Do We Use A Stack?
                            ~~~~~~~~~~~~~~~~~~~~~~

   Modern computers are designed with the need of high-level languages in
mind.  The most important technique for structuring programs introduced by
high-level languages is the procedure or function.  From one point of view, a
procedure call alters the flow of control just as a jump does, but unlike a
jump, when finished performing its task, a function returns control to the 
statement or instruction following the call.  This high-level abstraction
is implemented with the help of the stack.

  The stack is also used to dynamically allocate the local variables used in
functions, to pass parameters to the functions, and to return values from the
function.


                               The Stack Region
                               ~~~~~~~~~~~~~~~~

   A stack is a contiguous block of memory containing data.  A register called
the stack pointer (SP) points to the top of the stack.  The bottom of the 
stack is at a fixed address.  Its size is dynamically adjusted by the kernel 
at run time. The CPU implements instructions to PUSH onto and POP off of the 
stack. 

   The stack consists of logical stack frames that are pushed when calling a
function and popped when returning.  A stack frame contains the parameters to 
a function, its local variables, and the data necessary to recover the 
previous stack frame, including the value of the instruction pointer at the 
time of the function call.

   Depending on the implementation the stack will either grow down (towards
lower memory addresses), or up.  In our examples we'll use a stack that grows
down.  This is the way the stack grows on many computers including the Intel, 
Motorola, SPARC and MIPS processors.  The stack pointer (SP) is also
implementation dependent.  It may point to the last address on the stack, or 
to the next free available address after the stack.  For our discussion we'll
assume it points to the last address on the stack.

   In addition to the stack pointer, which points to the top of the stack
(lowest numerical address), it is often convenient to have a frame pointer
(FP) which points to a fixed location within a frame.  Some texts also refer
to it as a local base pointer (LB).  In principle, local variables could be
referenced by giving their offsets from SP.  However, as words are pushed onto
the stack and popped from the stack, these offsets change.  Although in some
cases the compiler can keep track of the number of words on the stack and
thus correct the offsets, in some cases it cannot, and in all cases
considerable administration is required.  Futhermore, on some machines, such
as Intel-based processors, accessing a variable at a known distance from SP
requires multiple instructions.

   Consequently, many compilers use a second register, FP, for referencing
both local variables and parameters because their distances from FP do
not change with PUSHes and POPs.  On Intel CPUs, BP (EBP) is used for this 
purpose.  On the Motorola CPUs, any address register except A7 (the stack 
pointer) will do.  Because the way our stack grows, actual parameters have 
positive offsets and local variables have negative offsets from FP.

   The first thing a procedure must do when called is save the previous FP
(so it can be restored at procedure exit).  Then it copies SP into FP to 
create the new FP, and advances SP to reserve space for the local variables. 
This code is called the procedure prolog.  Upon procedure exit, the stack 
must be cleaned up again, something called the procedure epilog.  The Intel 
ENTER and LEAVE instructions and the Motorola LINK and UNLINK instructions, 
have been provided to do most of the procedure prolog and epilog work 
efficiently. 

   Let us see what the stack looks like in a simple example:

example1.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
}

void main() {
  function(1,2,3);
}
------------------------------------------------------------------------------

   To understand what the program does to call function() we compile it with
gcc using the -S switch to generate assembly code output:

$ gcc -S -o example1.s example1.c

   By looking at the assembly language output we see that the call to
function() is translated to:

        pushl $3
        pushl $2
        pushl $1
        call function

    This pushes the 3 arguments to function backwards into the stack, and
calls function().  The instruction 'call' will push the instruction pointer
(IP) onto the stack.  We'll call the saved IP the return address (RET).  The
first thing done in function is the procedure prolog:

        pushl %ebp
        movl %esp,%ebp
        subl $20,%esp

   This pushes EBP, the frame pointer, onto the stack.  It then copies the
current SP onto EBP, making it the new FP pointer.  We'll call the saved FP
pointer SFP.  It then allocates space for the local variables by subtracting
their size from SP.

   We must remember that memory can only be addressed in multiples of the
word size.  A word in our case is 4 bytes, or 32 bits.  So our 5 byte buffer
is really going to take 8 bytes (2 words) of memory, and our 10 byte buffer
is going to take 12 bytes (3 words) of memory.  That is why SP is being
subtracted by 20.  With that in mind our stack looks like this when
function() is called (each space represents a byte):


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]
	   
top of                                                            bottom of
stack                                                                 stack


                               Buffer Overflows
                               ~~~~~~~~~~~~~~~~

   A buffer overflow is the result of stuffing more data into a buffer than
it can handle.  How can this often found programming error can be taken
advantage to execute arbitrary code?  Lets look at another example:

example2.c
------------------------------------------------------------------------------
void function(char *str) {
   char buffer[16];

   strcpy(buffer,str);
}

void main() {
  char large_string[256];
  int i;

  for( i = 0; i < 255; i++)
    large_string[i] = 'A';

  function(large_string);
}
------------------------------------------------------------------------------

   This is program has a function with a typical buffer overflow coding
error.  The function copies a supplied string without bounds checking by
using strcpy() instead of strncpy().  If you run this program you will get a
segmentation violation.  Lets see what its stack looks when we call function:


bottom of                                                            top of
memory                                                               memory
                  buffer            sfp   ret   *str
<------          [                ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   What is going on here?  Why do we get a segmentation violation?  Simple.
strcpy() is coping the contents of *str (larger_string[]) into buffer[]
until a null character is found on the string.  As we can see buffer[] is
much smaller than *str.  buffer[] is 16 bytes long, and we are trying to stuff
it with 256 bytes.  This means that all 250 bytes after buffer in the stack
are being overwritten.  This includes the SFP, RET, and even *str!  We had 
filled large_string with the character 'A'.  It's hex character value
is 0x41.  That means that the return address is now 0x41414141.  This is
outside of the process address space.  That is why when the function returns
and tries to read the next instruction from that address you get a 
segmentation violation.

   So a buffer overflow allows us to change the return address of a function.
In this way we can change the flow of execution of the program.  Lets go back
to our first example and recall what the stack looked like:


bottom of                                                            top of
memory                                                               memory
           buffer2       buffer1   sfp   ret   a     b     c
<------   [            ][        ][    ][    ][    ][    ][    ]

top of                                                            bottom of
stack                                                                 stack


   Lets try to modify our first example so that it overwrites the return
address, and demonstrate how we can make it execute arbitrary code.  Just
before buffer1[] on the stack is SFP, and before it, the return address.
That is 4 bytes pass the end of buffer1[].  But remember that buffer1[] is
really 2 word so its 8 bytes long.  So the return address is 12 bytes from
the start of buffer1[].  We'll modify the return value in such a way that the
assignment statement 'x = 1;' after the function call will be jumped.  To do
so we add 8 bytes to the return address.  Our code is now:

example3.c:
------------------------------------------------------------------------------
void function(int a, int b, int c) {
   char buffer1[5];
   char buffer2[10];
   int *ret;

   ret = buffer1 + 12;
   (*ret) += 8;
}

void main() {
  int x;

  x = 0;
  function(1,2,3);
  x = 1;
  printf("%d\n",x);
}
------------------------------------------------------------------------------

   What we have done is add 12 to buffer1[]'s address.  This new address is
where the return address is stored.  We want to skip pass the assignment to
the printf call.  How did we know to add 8 to the return address?  We used a
test value first (for example 1), compiled the program, and then started gdb:

------------------------------------------------------------------------------
[aleph1]$ gdb example3
GDB is free software and you are welcome to distribute copies of it
 under certain conditions; type "show copying" to see the conditions.
There is absolutely no warranty for GDB; type "show warranty" for details.
GDB 4.15 (i586-unknown-linux), Copyright 1995 Free Software Foundation, Inc...
(no debugging symbols found)...
(gdb) disassemble main
Dump of assembler code for function main:
0x8000490 <main>:       pushl  %ebp
0x8000491 <main+1>:     movl   %esp,%ebp
0x8000493 <main+3>:     subl   $0x4,%esp
0x8000496 <main+6>:     movl   $0x0,0xfffffffc(%ebp)
0x800049d <main+13>:    pushl  $0x3
0x800049f <main+15>:    pushl  $0x2
0x80004a1 <main+17>:    pushl  $0x1
0x80004a3 <main+19>:    call   0x8000470 <function>
0x80004a8 <main+24>:    addl   $0xc,%esp
0x80004ab <main+27>:    movl   $0x1,0xfffffffc(%ebp)
0x80004b2 <main+34>:    movl   0xfffffffc(%ebp),%eax
0x80004b5 <main+37>:    pushl  %eax
0x80004b6 <main+38>:    pushl  $0x80004f8
0x80004bb <main+43>:    call   0x8000378 <printf>
0x80004c0 <main+48>:    addl   $0x8,%esp
0x80004c3 <main+51>:    movl   %ebp,%esp
0x80004c5 <main+53>:    popl   %ebp
0x80004c6 <main+54>:    ret
0x80004c7 <main+55>:    nop
------------------------------------------------------------------------------

   We can see that when calling function() the RET will be 0x8004a8, and we
want to jump past the assignment at 0x80004ab.  The next instruction we want
to execute is the at 0x8004b2.  A little math tells us the distance is 8
bytes.


                                  Shell Code
                                  ~~~~~~~~~~

   So now that we know that we can modify the return address and the flow of
execution, what program do we want to execute?  In most cases we'll simply
want the program to spawn a shell.  From the shell we can then issue other
commands as we wish.  But what if there is no such code in the program we
are trying to exploit?  How can we place arbitrary instruction into its
address space?  The answer is to place the code with are trying to execute in
the buffer we are overflowing, and overwrite the return address so it points
back into the buffer.  Assuming the stack starts at address 0xFF, and that S
stands for the code we want to execute the stack would then look like this:


bottom of  DDDDDDDDEEEEEEEEEEEE  EEEE  FFFF  FFFF  FFFF  FFFF     top of
memory     89ABCDEF0123456789AB  CDEF  0123  4567  89AB  CDEF     memory
           buffer                sfp   ret   a     b     c

<------   [SSSSSSSSSSSSSSSSSSSS][SSSS][0xD8][0x01][0x02][0x03]
           ^                            |
           |____________________________|
top of                                                            bottom of
stack                                                                 stack


The code to spawn a shell in C looks like:

shellcode.c
-----------------------------------------------------------------------------
#include <stdio.h>

void main() {
   char *name[2];

   name[0] = "/bin/sh";
   name[1] = NULL;
   execve(name[0], name, NULL);
}
------------------------------------------------------------------------------

   To find out what does it looks like in assembly we compile it, and start
up gdb.  Remember to use the -static flag. Otherwise the actual code the
for the execve system call will not be included.  Instead there will be a
reference to dynamic C library that would normally would be linked in at
load time.

------------------------------------------------------------------------------
[aleph1]$ gcc -o shellcode -ggdb -static shellcode.c






</p>
<p>
fsfhd</p>
</body>
</html>